{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cf3a6f",
   "metadata": {
    "papermill": {
     "duration": 0.003492,
     "end_time": "2026-02-03T02:38:50.945485",
     "exception": false,
     "start_time": "2026-02-03T02:38:50.941993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ALG Sequential Solver for AIMO3\n",
    "\n",
    "Adaptive Lemma Graph solver with:\n",
    "1. **Problem Classification** - Model determines topic and complexity\n",
    "2. **Topic-Specific DAG** - Build lemma graph based on problem type\n",
    "3. **Dynamic Time Allocation** - Spend more time on hard problems\n",
    "4. **Sequential Traversal** - No parallel threads, one rigorous proof path\n",
    "\n",
    "Strategy:\n",
    "- Simple problems (2-3 lemmas): ~60 seconds\n",
    "- Medium problems (4-5 lemmas): ~180 seconds\n",
    "- Hard problems (6-8 lemmas): ~480 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3975a754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:38:50.951980Z",
     "iopub.status.busy": "2026-02-03T02:38:50.951758Z",
     "iopub.status.idle": "2026-02-03T02:40:05.192367Z",
     "shell.execute_reply": "2026-02-03T02:40:05.191843Z"
    },
    "papermill": {
     "duration": 74.245402,
     "end_time": "2026-02-03T02:40:05.193649",
     "exception": false,
     "start_time": "2026-02-03T02:38:50.948247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.10.0\r\n",
      "Uninstalling keras-3.10.0:\r\n",
      "  Successfully uninstalled keras-3.10.0\r\n",
      "Found existing installation: matplotlib 3.10.0\r\n",
      "Uninstalling matplotlib-3.10.0:\r\n",
      "  Successfully uninstalled matplotlib-3.10.0\r\n",
      "Found existing installation: scikit-learn 1.6.1\r\n",
      "Uninstalling scikit-learn-1.6.1:\r\n",
      "  Successfully uninstalled scikit-learn-1.6.1\r\n",
      "Found existing installation: tensorflow 2.19.0\r\n",
      "Uninstalling tensorflow-2.19.0:\r\n",
      "  Successfully uninstalled tensorflow-2.19.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall --yes 'keras' 'matplotlib' 'scikit-learn' 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe6b3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:40:05.200569Z",
     "iopub.status.busy": "2026-02-03T02:40:05.200383Z",
     "iopub.status.idle": "2026-02-03T02:40:05.203084Z",
     "shell.execute_reply": "2026-02-03T02:40:05.202734Z"
    },
    "papermill": {
     "duration": 0.007113,
     "end_time": "2026-02-03T02:40:05.203867",
     "exception": false,
     "start_time": "2026-02-03T02:40:05.196754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd4fce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:40:05.210213Z",
     "iopub.status.busy": "2026-02-03T02:40:05.210058Z",
     "iopub.status.idle": "2026-02-03T02:40:05.213014Z",
     "shell.execute_reply": "2026-02-03T02:40:05.212656Z"
    },
    "papermill": {
     "duration": 0.007049,
     "end_time": "2026-02-03T02:40:05.213767",
     "exception": false,
     "start_time": "2026-02-03T02:40:05.206718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_env(input_archive, temp_dir):\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "        subprocess.run(['tar', '-xzf', input_archive, '-C', temp_dir], check=True)\n",
    "    \n",
    "    subprocess.run([\n",
    "        sys.executable,\n",
    "        '-m',\n",
    "        'pip',\n",
    "        'install',\n",
    "        '--no-index',\n",
    "        '--find-links',\n",
    "        f'{temp_dir}/wheels',\n",
    "        'unsloth',\n",
    "        'trl',\n",
    "        'vllm',\n",
    "        'openai_harmony'\n",
    "    ], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159bdb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:40:05.219834Z",
     "iopub.status.busy": "2026-02-03T02:40:05.219554Z",
     "iopub.status.idle": "2026-02-03T02:43:31.711266Z",
     "shell.execute_reply": "2026-02-03T02:43:31.710810Z"
    },
    "papermill": {
     "duration": 206.50119,
     "end_time": "2026-02-03T02:43:31.717586",
     "exception": false,
     "start_time": "2026-02-03T02:40:05.216396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/tmp/setup/wheels\n",
      "Processing /kaggle/tmp/setup/wheels/unsloth-2025.12.9-py3-none-any.whl\n",
      "Processing /kaggle/tmp/setup/wheels/trl-0.24.0-py3-none-any.whl\n",
      "Processing /kaggle/tmp/setup/wheels/vllm-0.11.2-cp38-abi3-manylinux1_x86_64.whl\n",
      "Processing /kaggle/tmp/setup/wheels/openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Processing /kaggle/tmp/setup/wheels/unsloth_zoo-2025.12.7-py3-none-any.whl (from unsloth)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (26.0rc2)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
      "Processing /kaggle/tmp/setup/wheels/tyro-1.0.3-py3-none-any.whl (from unsloth)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
      "Processing /kaggle/tmp/setup/wheels/xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl (from unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (from unsloth)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
      "Processing /kaggle/tmp/setup/wheels/datasets-4.3.0-py3-none-any.whl (from unsloth)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.11.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2025.11.3)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (5.5.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.5)\n",
      "Requirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.0.8)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.123.10)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.3)\n",
      "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.15.0)\n",
      "Requirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.5)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n",
      "Processing /kaggle/tmp/setup/wheels/prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (from vllm)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n",
      "Processing /kaggle/tmp/setup/wheels/lm_format_enforcer-0.11.3-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/diskcache-5.6.3-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/lark-1.2.2-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.3)\n",
      "Processing /kaggle/tmp/setup/wheels/partial_json_parser-0.2.1.1.post7-py3-none-any.whl (from vllm)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
      "Processing /kaggle/tmp/setup/wheels/msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/gguf-0.17.1-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/mistral_common-1.8.8-py3-none-any.whl (from mistral_common[image]>=1.8.5->vllm)\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n",
      "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
      "Processing /kaggle/tmp/setup/wheels/setuptools-80.9.0-py3-none-any.whl (from vllm)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
      "Processing /kaggle/tmp/setup/wheels/compressed_tensors-0.12.2-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/depyf-0.20.0-py3-none-any.whl (from vllm)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.1)\n",
      "Processing /kaggle/tmp/setup/wheels/watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.15.3)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm) (1.13.0)\n",
      "Processing /kaggle/tmp/setup/wheels/pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/anthropic-0.71.0-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/model_hosting_container_standards-0.1.12-py3-none-any.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from vllm)\n",
      "Requirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (2.53.0)\n",
      "Processing /kaggle/tmp/setup/wheels/torch-2.9.0+cu128-cp312-cp312-manylinux_2_28_x86_64.whl (from unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/torchaudio-2.9.0+cu128-cp312-cp312-manylinux_2_28_x86_64.whl (from vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/torchvision-0.24.0+cu128-cp312-cp312-manylinux_2_28_x86_64.whl (from unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/flashinfer_python-0.5.2-py3-none-any.whl (from vllm)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.17.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.3.1)\n",
      "Processing /kaggle/tmp/setup/wheels/loguru-0.7.3-py3-none-any.whl (from compressed-tensors==0.12.2->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/astor-0.8.1-py2.py3-none-any.whl (from depyf==0.20.0->vllm)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.4.0)\n",
      "Processing /kaggle/tmp/setup/wheels/apache_tvm_ffi-0.1.7-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (from flashinfer-python==0.5.2->vllm)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (8.3.1)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cudnn_frontend-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (from flashinfer-python==0.5.2->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cutlass_dsl-4.3.4-cp312-cp312-manylinux_2_28_x86_64.whl (from flashinfer-python==0.5.2->vllm)\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (12.575.51)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (0.9.0)\n",
      "Processing /kaggle/tmp/setup/wheels/interegular-0.3.3-py37-none-any.whl (from lm-format-enforcer==0.11.3->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from numba==0.61.2->vllm)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2025.10.0)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch>=2.4.0->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (from unsloth)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.6.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Processing /kaggle/tmp/setup/wheels/multiprocess-0.70.16-py312-none-any.whl (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/fsspec-2025.9.0-py3-none-any.whl (from torch>=2.4.0->unsloth)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.0.4)\n",
      "Processing /kaggle/tmp/setup/wheels/fastapi_cli-0.0.20-py3-none-any.whl (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.3.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.1rc0)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (4.25.1)\n",
      "Processing /kaggle/tmp/setup/wheels/pydantic_extra_types-2.10.6-py3-none-any.whl (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
      "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0->vllm) (1.0.1)\n",
      "Processing /kaggle/tmp/setup/wheels/supervisor-4.3.0-py2.py3-none-any.whl (from model-hosting-container-standards<1.0.0->vllm)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.4.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n",
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2026.1.4)\n",
      "Processing /kaggle/tmp/setup/wheels/torchao-0.15.0+cu128-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (from unsloth_zoo>=2025.12.7->unsloth)\n",
      "Processing /kaggle/tmp/setup/wheels/cut_cross_entropy-25.1.1-py3-none-any.whl (from unsloth_zoo>=2025.12.7->unsloth)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.8.0)\n",
      "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\n",
      "Processing /kaggle/tmp/setup/wheels/rich_toolkit-0.17.1-py3-none-any.whl (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/fastapi_cloud_cli-0.8.0-py3-none-any.whl (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.27.1)\n",
      "Processing /kaggle/tmp/setup/wheels/cuda_python-13.1.1-py3-none-any.whl (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/pycountry-24.6.1-py3-none-any.whl (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Processing /kaggle/tmp/setup/wheels/httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
      "Processing /kaggle/tmp/setup/wheels/uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Processing /kaggle/tmp/setup/wheels/cuda_bindings-13.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/cuda_pathfinder-1.3.3-py3-none-any.whl (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm)\n",
      "Processing /kaggle/tmp/setup/wheels/rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.42.1)\n",
      "Processing /kaggle/tmp/setup/wheels/fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.2.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "Installing collected packages: torchao, supervisor, uvloop, triton, setuptools, setproctitle, rignore, pycountry, pybase64, partial-json-parser, outlines_core, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cudnn-frontend, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, loguru, llvmlite, llguidance, lark, interegular, httptools, gguf, fsspec, fastar, diskcache, cuda-pathfinder, cbor2, astor, apache-tvm-ffi, watchfiles, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, numba, depyf, cuda-bindings, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai_harmony, nvidia-cusolver-cu12, lm-format-enforcer, cuda-python, anthropic, torch, nvidia-cutlass-dsl, model-hosting-container-standards, fastapi-cloud-cli, fastapi-cli, datasets, xgrammar, xformers, torchvision, torchaudio, mistral_common, flashinfer-python, cut_cross_entropy, compressed-tensors, bitsandbytes, trl, unsloth_zoo, vllm, unsloth\n",
      "  Attempting uninstall: torchao\n",
      "    Found existing installation: torchao 0.10.0\n",
      "    Uninstalling torchao-0.10.0:\n",
      "      Successfully uninstalled torchao-0.10.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.4.0\n",
      "    Uninstalling triton-3.4.0:\n",
      "      Successfully uninstalled triton-3.4.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nvshmem-cu12\n",
      "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
      "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
      "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
      "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.18\n",
      "    Uninstalling multiprocess-0.70.18:\n",
      "      Successfully uninstalled multiprocess-0.70.18\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.43.0\n",
      "    Uninstalling llvmlite-0.43.0:\n",
      "      Successfully uninstalled llvmlite-0.43.0\n",
      "  Attempting uninstall: lark\n",
      "    Found existing installation: lark 1.3.0\n",
      "    Uninstalling lark-1.3.0:\n",
      "      Successfully uninstalled lark-1.3.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.10.0\n",
      "    Uninstalling fsspec-2025.10.0:\n",
      "      Successfully uninstalled fsspec-2025.10.0\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.60.0\n",
      "    Uninstalling numba-0.60.0:\n",
      "      Successfully uninstalled numba-0.60.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: cuda-python\n",
      "    Found existing installation: cuda-python 12.6.2.post1\n",
      "    Uninstalling cuda-python-12.6.2.post1:\n",
      "      Successfully uninstalled cuda-python-12.6.2.post1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0+cu126\n",
      "    Uninstalling torch-2.8.0+cu126:\n",
      "      Successfully uninstalled torch-2.8.0+cu126\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.4.2\n",
      "    Uninstalling datasets-4.4.2:\n",
      "      Successfully uninstalled datasets-4.4.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.23.0+cu126\n",
      "    Uninstalling torchvision-0.23.0+cu126:\n",
      "      Successfully uninstalled torchvision-0.23.0+cu126\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.8.0+cu126\n",
      "    Uninstalling torchaudio-2.8.0+cu126:\n",
      "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
      "Successfully installed anthropic-0.71.0 apache-tvm-ffi-0.1.7 astor-0.8.1 bitsandbytes-0.49.0 cbor2-5.7.1 compressed-tensors-0.12.2 cuda-bindings-13.1.1 cuda-pathfinder-1.3.3 cuda-python-13.1.1 cut_cross_entropy-25.1.1 datasets-4.3.0 depyf-0.20.0 diskcache-5.6.3 fastapi-cli-0.0.20 fastapi-cloud-cli-0.8.0 fastar-0.8.0 flashinfer-python-0.5.2 fsspec-2025.9.0 gguf-0.17.1 httptools-0.7.1 interegular-0.3.3 lark-1.2.2 llguidance-1.3.0 llvmlite-0.44.0 lm-format-enforcer-0.11.3 loguru-0.7.3 mistral_common-1.8.8 model-hosting-container-standards-0.1.12 msgspec-0.20.0 multiprocess-0.70.16 numba-0.61.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-frontend-1.17.0 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cutlass-dsl-4.3.4 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 openai_harmony-0.0.8 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post7 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.3 pycountry-24.6.1 pydantic-extra-types-2.10.6 rich-toolkit-0.17.1 rignore-0.7.6 setproctitle-1.3.7 setuptools-80.9.0 supervisor-4.3.0 torch-2.9.0+cu128 torchao-0.15.0+cu128 torchaudio-2.9.0+cu128 torchvision-0.24.0+cu128 triton-3.5.0 trl-0.24.0 tyro-1.0.3 unsloth-2025.12.9 unsloth_zoo-2025.12.7 uvloop-0.22.1 vllm-0.11.2 watchfiles-1.1.1 xformers-0.0.33.post1 xgrammar-0.1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyldavis 3.4.1 requires scikit-learn>=1.0.0, which is not installed.\n",
      "ydata-profiling 4.18.1 requires matplotlib<=3.10,>=3.5, which is not installed.\n",
      "stable-baselines3 2.1.0 requires matplotlib, which is not installed.\n",
      "sentence-transformers 5.1.1 requires scikit-learn, which is not installed.\n",
      "librosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\n",
      "cuml-cu12 25.6.0 requires scikit-learn>=1.5, which is not installed.\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "bigframes 2.26.0 requires matplotlib>=3.7.1, which is not installed.\n",
      "arviz 0.22.0 requires matplotlib>=3.8, which is not installed.\n",
      "pynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\n",
      "shap 0.49.1 requires scikit-learn, which is not installed.\n",
      "fastai 2.8.4 requires matplotlib, which is not installed.\n",
      "fastai 2.8.4 requires scikit-learn, which is not installed.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, which is not installed.\n",
      "cudf-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
      "cuml-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "pylibraft-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "cuvs-cu12 25.6.1 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "fastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cu128 which is incompatible.\n",
      "rmm-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires cuda-python<13.0a0,>=12.6.2, but you have cuda-python 13.1.1 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "set_env(\n",
    "    input_archive='/kaggle/input/aimo-3-utils/wheels.tar.gz',\n",
    "    temp_dir='/kaggle/tmp/setup'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ec75e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:31.729030Z",
     "iopub.status.busy": "2026-02-03T02:43:31.728654Z",
     "iopub.status.idle": "2026-02-03T02:43:31.731517Z",
     "shell.execute_reply": "2026-02-03T02:43:31.731147Z"
    },
    "papermill": {
     "duration": 0.009925,
     "end_time": "2026-02-03T02:43:31.732368",
     "exception": false,
     "start_time": "2026-02-03T02:43:31.722443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_NO_TF'] = '1'\n",
    "os.environ['TRANSFORMERS_NO_FLAX'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['TRITON_PTXAS_PATH'] = '/usr/local/cuda/bin/ptxas'\n",
    "os.environ['TIKTOKEN_ENCODINGS_BASE'] = '/kaggle/tmp/setup/tiktoken_encodings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f769f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:31.742882Z",
     "iopub.status.busy": "2026-02-03T02:43:31.742719Z",
     "iopub.status.idle": "2026-02-03T02:43:39.585573Z",
     "shell.execute_reply": "2026-02-03T02:43:39.585060Z"
    },
    "papermill": {
     "duration": 7.84921,
     "end_time": "2026-02-03T02:43:39.586509",
     "exception": false,
     "start_time": "2026-02-03T02:43:31.737299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports done\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import queue\n",
    "import threading\n",
    "import contextlib\n",
    "import traceback\n",
    "from typing import Optional, List, Dict, Tuple, Any\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from openai_harmony import (\n",
    "    HarmonyEncodingName,\n",
    "    load_harmony_encoding,\n",
    "    SystemContent,\n",
    "    ReasoningEffort,\n",
    "    ToolNamespaceConfig,\n",
    "    Author,\n",
    "    Message,\n",
    "    Role,\n",
    "    TextContent,\n",
    "    Conversation\n",
    ")\n",
    "\n",
    "from transformers import set_seed\n",
    "import kaggle_evaluation.aimo_3_inference_server\n",
    "\n",
    "print('All imports done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc90588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.598079Z",
     "iopub.status.busy": "2026-02-03T02:43:39.597821Z",
     "iopub.status.idle": "2026-02-03T02:43:39.605194Z",
     "shell.execute_reply": "2026-02-03T02:43:39.604772Z"
    },
    "papermill": {
     "duration": 0.014129,
     "end_time": "2026-02-03T02:43:39.606041",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.591912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration with domain knowledge loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION WITH DOMAIN KNOWLEDGE\n",
    "# ============================================================\n",
    "\n",
    "class CFG:\n",
    "    # Model settings\n",
    "    model_path = '/kaggle/input/gpt-oss-120b/transformers/default/1'\n",
    "    served_model_name = 'gpt-oss'\n",
    "    \n",
    "    # Inference settings\n",
    "    context_tokens = 65536\n",
    "    temperature = 0.7\n",
    "    top_p = 0.95\n",
    "    max_tokens_per_turn = 4096\n",
    "    \n",
    "    # Time budgets (seconds) based on complexity\n",
    "    time_budget = {\n",
    "        'simple': 60,\n",
    "        'medium': 180,\n",
    "        'hard': 480,\n",
    "        'default': 180\n",
    "    }\n",
    "    \n",
    "    # Lemma settings\n",
    "    max_lemmas = 8\n",
    "    max_retries_per_lemma = 3\n",
    "    \n",
    "    # Python sandbox\n",
    "    sandbox_timeout = 30\n",
    "    \n",
    "    # Server settings\n",
    "    server_port = 8000\n",
    "    server_timeout = 180\n",
    "    \n",
    "    # vLLM settings\n",
    "    kv_cache_dtype = 'fp8_e4m3'\n",
    "    dtype = 'auto'\n",
    "    gpu_memory_utilization = 0.96\n",
    "    batch_size = 256\n",
    "    \n",
    "    # Comprehensive domain knowledge for IMO problems\n",
    "    DOMAIN_KNOWLEDGE = {\n",
    "        'algebra': {\n",
    "            'description': 'Algebraic manipulation, equations, inequalities, polynomials',\n",
    "            'common_techniques': [\n",
    "                'Factorization and expansion',\n",
    "                'Substitution and change of variables',\n",
    "                'AM-GM inequality, Cauchy-Schwarz inequality',\n",
    "                \"Vieta's formulas for polynomials\",\n",
    "                'Symmetric sums and elementary symmetric polynomials',\n",
    "                'Telescoping sums and products',\n",
    "                'Completing the square',\n",
    "                'Functional equations',\n",
    "                'Inequalities (Chebyshev, Holder, Minkowski)'\n",
    "            ],\n",
    "            'common_patterns': [\n",
    "                'Look for symmetry in expressions',\n",
    "                'Consider substitution to simplify',\n",
    "                'Use inequalities to bound expressions',\n",
    "                'Factor polynomials to find roots',\n",
    "                'Look for telescoping patterns in sums'\n",
    "            ],\n",
    "            'verification_strategies': [\n",
    "                'Check with specific numerical examples',\n",
    "                'Verify inequalities at boundary cases',\n",
    "                'Test polynomial identities with random values',\n",
    "                'Use symbolic computation for expansions'\n",
    "            ]\n",
    "        },\n",
    "        'number_theory': {\n",
    "            'description': 'Properties of integers, divisibility, primes, modular arithmetic',\n",
    "            'common_techniques': [\n",
    "                'Modular arithmetic (mod n)',\n",
    "                'Chinese remainder theorem',\n",
    "                \"Fermat's little theorem and Euler's theorem\",\n",
    "                'Euclidean algorithm and Bezout identity',\n",
    "                'Prime factorization and unique factorization',\n",
    "                'Order of elements modulo n',\n",
    "                'Legendre symbol and quadratic reciprocity',\n",
    "                'Divisibility rules and properties',\n",
    "                'Pell equations and Diophantine equations'\n",
    "            ],\n",
    "            'common_patterns': [\n",
    "                'Check parity (even/odd)',\n",
    "                'Consider remainders modulo small numbers',\n",
    "                'Look for prime factorization patterns',\n",
    "                'Use divisibility chains',\n",
    "                'Consider greatest common divisors'\n",
    "            ],\n",
    "            'verification_strategies': [\n",
    "                'Test with small numerical examples',\n",
    "                'Verify divisibility properties',\n",
    "                'Check modular arithmetic calculations',\n",
    "                'Use brute force for small ranges'\n",
    "            ]\n",
    "        },\n",
    "        'combinatorics': {\n",
    "            'description': 'Counting, arrangements, graphs, combinatorial structures',\n",
    "            'common_techniques': [\n",
    "                'Pigeonhole principle',\n",
    "                'Double counting arguments',\n",
    "                'Inclusion-exclusion principle',\n",
    "                'Generating functions',\n",
    "                'Recurrence relations',\n",
    "                'Graph theory concepts',\n",
    "                'Bijections and combinatorial proofs',\n",
    "                'Ramsey theory',\n",
    "                'Probabilistic method'\n",
    "            ],\n",
    "            'common_patterns': [\n",
    "                'Look for invariant quantities',\n",
    "                'Consider extreme cases',\n",
    "                'Use symmetry to simplify counting',\n",
    "                'Look for recursive structure',\n",
    "                'Consider graph representations'\n",
    "            ],\n",
    "            'verification_strategies': [\n",
    "                'Count small cases manually',\n",
    "                'Verify recurrence relations',\n",
    "                'Check combinatorial identities',\n",
    "                'Use computational enumeration for small n'\n",
    "            ]\n",
    "        },\n",
    "        'geometry': {\n",
    "            'description': 'Shapes, angles, lengths, coordinates, transformations',\n",
    "            'common_techniques': [\n",
    "                'Coordinate geometry',\n",
    "                'Vector methods',\n",
    "                'Trigonometry and trigonometric identities',\n",
    "                'Similarity and congruence',\n",
    "                'Power of a point',\n",
    "                'Circle theorems (inscribed angles, cyclic quadrilaterals)',\n",
    "                'Triangle geometry (cevians, medians, altitudes)',\n",
    "                'Transformations (rotations, reflections, homothety)',\n",
    "                'Complex numbers in geometry'\n",
    "            ],\n",
    "            'common_patterns': [\n",
    "                'Add auxiliary lines',\n",
    "                'Use coordinate system wisely',\n",
    "                'Look for similar triangles',\n",
    "                'Consider symmetry',\n",
    "                'Use angle chasing'\n",
    "            ],\n",
    "            'verification_strategies': [\n",
    "                'Verify with specific coordinates',\n",
    "                'Check trigonometric identities',\n",
    "                'Use geometric software for verification',\n",
    "                'Test with special cases'\n",
    "            ]\n",
    "        },\n",
    "        'analysis': {\n",
    "            'description': 'Limits, continuity, sequences, series, inequalities',\n",
    "            'common_techniques': [\n",
    "                'Epsilon-delta arguments',\n",
    "                'Mean value theorem and Taylor series',\n",
    "                'Monotonic sequences and convergence',\n",
    "                'Inequalities (Jensen, Chebyshev, rearrangement)',\n",
    "                'Functional equations',\n",
    "                'Recurrence relations for sequences',\n",
    "                'Asymptotic analysis',\n",
    "                'Fixed point theorems',\n",
    "                'Continuity and intermediate value property'\n",
    "            ],\n",
    "            'common_patterns': [\n",
    "                'Look for monotonicity',\n",
    "                'Consider limiting behavior',\n",
    "                'Use telescoping in sequences',\n",
    "                'Apply known inequalities',\n",
    "                'Check special values'\n",
    "            ],\n",
    "            'verification_strategies': [\n",
    "                'Test with numerical sequences',\n",
    "                'Verify inequalities numerically',\n",
    "                'Check continuity at sample points',\n",
    "                'Use computational limits'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Common IMO problem solving strategies\n",
    "    IMO_STRATEGIES = [\n",
    "        'Look for invariant or monovariant quantities',\n",
    "        'Consider extreme cases or boundary conditions',\n",
    "        'Use symmetry to reduce complexity',\n",
    "        'Try small cases to find pattern',\n",
    "        'Assume opposite and seek contradiction',\n",
    "        'Use induction (mathematical, strong, or structural)',\n",
    "        'Apply probabilistic method',\n",
    "        'Construct explicit examples or counterexamples',\n",
    "        'Use double counting arguments',\n",
    "        'Employ generating functions or recurrence relations'\n",
    "    ]\n",
    "\n",
    "print('Configuration with domain knowledge loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7423f37e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.617140Z",
     "iopub.status.busy": "2026-02-03T02:43:39.616973Z",
     "iopub.status.idle": "2026-02-03T02:43:39.620749Z",
     "shell.execute_reply": "2026-02-03T02:43:39.620383Z"
    },
    "papermill": {
     "duration": 0.01033,
     "end_time": "2026-02-03T02:43:39.621552",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.611222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ffb130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.632353Z",
     "iopub.status.busy": "2026-02-03T02:43:39.632201Z",
     "iopub.status.idle": "2026-02-03T02:43:39.636239Z",
     "shell.execute_reply": "2026-02-03T02:43:39.635850Z"
    },
    "papermill": {
     "duration": 0.010558,
     "end_time": "2026-02-03T02:43:39.637065",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.626507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts with domain knowledge defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# JSON OUTPUT PROMPTS WITH DOMAIN KNOWLEDGE\n",
    "# ============================================================\n",
    "\n",
    "CLASSIFICATION_PROMPT = \"\"\"You are an expert IMO problem classifier. Analyze this mathematical problem and output ONLY valid JSON.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Domain Knowledge Context:\n",
    "{domain_context}\n",
    "\n",
    "Output JSON format:\n",
    "{{\n",
    "  \"topic\": \"algebra|number_theory|combinatorics|geometry|analysis\",\n",
    "  \"complexity\": \"simple|medium|hard\",\n",
    "  \"key_techniques\": [\"technique1\", \"technique2\", \"technique3\"],\n",
    "  \"estimated_lemmas\": 4,\n",
    "  \"reasoning\": \"brief explanation\",\n",
    "  \"confidence\": 0.95\n",
    "}}\n",
    "\n",
    "Guidelines:\n",
    "- Simple: Direct, few steps (< 5 min for expert)\n",
    "- Medium: Requires insight, multiple steps (5-15 min)\n",
    "- Hard: Deep insight, creative approach (> 15 min)\n",
    "- Choose techniques from domain knowledge\n",
    "- Confidence between 0.0 and 1.0\n",
    "\"\"\"\n",
    "\n",
    "LEMMA_GRAPH_PROMPT = \"\"\"You are an IMO Gold Medalist. Decompose this problem into a lemma graph. Output ONLY valid JSON.\n",
    "\n",
    "Problem: {problem}\n",
    "Topic: {topic}\n",
    "Complexity: {complexity}\n",
    "Target Lemma Count: {estimated_lemmas}\n",
    "\n",
    "Domain Knowledge for {topic}:\n",
    "{domain_knowledge}\n",
    "\n",
    "IMO Strategies to Consider:\n",
    "{imo_strategies}\n",
    "\n",
    "Output JSON format:\n",
    "{{\n",
    "  \"lemmas\": [\n",
    "    {{\n",
    "      \"id\": \"L1\",\n",
    "      \"statement\": \"mathematical statement\",\n",
    "      \"type\": \"structural|reduction|computational|inequality|existence|counting|verification\",\n",
    "      \"dependencies\": [],\n",
    "      \"purpose\": \"why this lemma is needed\",\n",
    "      \"verification_strategy\": \"how to verify this lemma\",\n",
    "      \"domain_hint\": \"which domain technique applies\"\n",
    "    }},\n",
    "    ...\n",
    "  ],\n",
    "  \"final_lemma\": {{\n",
    "    \"id\": \"FINAL\",\n",
    "    \"statement\": \"Synthesize solution from all lemmas\",\n",
    "    \"type\": \"synthesis\",\n",
    "    \"dependencies\": [\"L1\", \"L2\", ...],\n",
    "    \"purpose\": \"Combine verified lemmas to solve original problem\"\n",
    "  }},\n",
    "  \"graph_strategy\": \"explanation of decomposition approach\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "1. Dependencies must form a DAG (no cycles)\n",
    "2. Use domain-appropriate techniques\n",
    "3. Each lemma should be mathematically precise\n",
    "4. Consider IMO problem-solving strategies\n",
    "\"\"\"\n",
    "\n",
    "LEMMA_PROOF_PROMPT = \"\"\"You are a mathematical proof assistant. Prove this lemma and provide verification. Output ONLY valid JSON.\n",
    "\n",
    "Problem Context: {problem}\n",
    "Lemma ID: {lemma_id}\n",
    "Lemma Statement: {lemma_statement}\n",
    "Lemma Type: {lemma_type}\n",
    "Purpose: {purpose}\n",
    "\n",
    "Domain: {topic}\n",
    "Domain Techniques: {domain_techniques}\n",
    "\n",
    "Output JSON format:\n",
    "{{\n",
    "  \"proof\": \"step-by-step mathematical proof\",\n",
    "  \"verification_code\": \"python code to verify (if applicable, else empty string)\",\n",
    "  \"verification_explanation\": \"how verification works\",\n",
    "  \"confidence\": 0.95,\n",
    "  \"key_insights\": [\"insight1\", \"insight2\"]\n",
    "}}\n",
    "\n",
    "Guidelines:\n",
    "- Proof must be mathematically rigorous\n",
    "- Include all necessary steps\n",
    "- If computational lemma, provide Python code\n",
    "- If theoretical lemma, explain verification strategy\n",
    "- Confidence based on proof completeness\n",
    "\"\"\"\n",
    "\n",
    "SOLUTION_PROMPT = \"\"\"You are an IMO Gold Medalist. Solve this problem using the verified lemmas. Output ONLY valid JSON.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Domain: {topic}\n",
    "Domain Knowledge: {domain_knowledge}\n",
    "\n",
    "Verified Lemmas Summary:\n",
    "{lemmas_summary}\n",
    "\n",
    "Output JSON format:\n",
    "{{\n",
    "  \"solution_analysis\": \"how lemmas combine to solve problem\",\n",
    "  \"step_by_step_solution\": \"complete mathematical solution\",\n",
    "  \"answer\": 123,\n",
    "  \"confidence\": 0.95,\n",
    "  \"verification_checks\": [\"check1\", \"check2\"],\n",
    "  \"alternative_approaches\": [\"approach1\", \"approach2\"]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "1. Answer must be an integer (or 0 if unknown)\n",
    "2. Confidence between 0.0 and 1.0\n",
    "3. Show how lemmas are used\n",
    "4. Include verification of answer\n",
    "5. Consider edge cases\n",
    "\"\"\"\n",
    "\n",
    "DIRECT_SOLUTION_PROMPT = \"\"\"You are an IMO Gold Medalist. Solve this problem directly. Output ONLY valid JSON.\n",
    "\n",
    "Problem: {problem}\n",
    "Topic: {topic}\n",
    "\n",
    "Domain Knowledge for {topic}:\n",
    "{domain_knowledge}\n",
    "\n",
    "IMO Strategies:\n",
    "{imo_strategies}\n",
    "\n",
    "Output JSON format:\n",
    "{{\n",
    "  \"problem_analysis\": \"understanding of problem structure\",\n",
    "  \"solution_strategy\": \"chosen approach and why\",\n",
    "  \"mathematical_proof\": \"complete rigorous proof\",\n",
    "  \"answer\": 123,\n",
    "  \"confidence\": 0.95,\n",
    "  \"verification\": \"how answer was verified\",\n",
    "  \"edge_cases_checked\": [\"case1\", \"case2\"]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "1. Provide complete mathematical proof\n",
    "2. Answer must be an integer\n",
    "3. Confidence between 0.0 and 1.0\n",
    "4. Check all edge cases\n",
    "5. Verify answer makes sense\n",
    "\"\"\"\n",
    "\n",
    "print('Prompts with domain knowledge defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbc626c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.647820Z",
     "iopub.status.busy": "2026-02-03T02:43:39.647665Z",
     "iopub.status.idle": "2026-02-03T02:43:39.658799Z",
     "shell.execute_reply": "2026-02-03T02:43:39.658393Z"
    },
    "papermill": {
     "duration": 0.017705,
     "end_time": "2026-02-03T02:43:39.659669",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.641964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structures defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIMPLE DATA STRUCTURES\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class ProblemClassification:\n",
    "    topic: str\n",
    "    complexity: str  # \"simple\", \"medium\", \"hard\"\n",
    "    key_techniques: List[str] = field(default_factory=list)\n",
    "    estimated_lemmas: int = 4\n",
    "    reasoning: str = ''\n",
    "    confidence: float = 0.0\n",
    "    \n",
    "    def get_time_budget(self) -> float:\n",
    "        return CFG.time_budget.get(self.complexity, CFG.time_budget['default'])\n",
    "    \n",
    "    def get_domain_info(self) -> Dict:\n",
    "        \"\"\"Get domain knowledge for this topic\"\"\"\n",
    "        return CFG.DOMAIN_KNOWLEDGE.get(self.topic, CFG.DOMAIN_KNOWLEDGE['algebra'])\n",
    "\n",
    "@dataclass\n",
    "class Lemma:\n",
    "    id: str\n",
    "    statement: str\n",
    "    lemma_type: str\n",
    "    dependencies: List[str] = field(default_factory=list)\n",
    "    purpose: str = ''\n",
    "    verification_strategy: str = ''\n",
    "    domain_hint: str = ''\n",
    "    proof: str = ''\n",
    "    verification_code: str = ''\n",
    "    execution_result: Optional[str] = None\n",
    "    verified: bool = False\n",
    "    confidence: float = 0.0\n",
    "    \n",
    "    def to_summary(self) -> str:\n",
    "        status = \"\" if self.verified else \"?\"\n",
    "        return f\"{status} {self.id} ({self.lemma_type}): {self.statement[:80]}...\"\n",
    "\n",
    "@dataclass \n",
    "class LemmaGraph:\n",
    "    problem: str\n",
    "    classification: ProblemClassification\n",
    "    lemmas: Dict[str, Lemma] = field(default_factory=dict)\n",
    "    final_lemma: Optional[Lemma] = None\n",
    "    graph_strategy: str = ''\n",
    "    \n",
    "    def get_dependency_order(self) -> List[str]:\n",
    "        \"\"\"Topological sort of lemmas\"\"\"\n",
    "        if not self.lemmas:\n",
    "            return []\n",
    "        \n",
    "        # Build adjacency and in-degree\n",
    "        adj = {lid: [] for lid in self.lemmas}\n",
    "        in_deg = {lid: 0 for lid in self.lemmas}\n",
    "        \n",
    "        for lemma in self.lemmas.values():\n",
    "            for dep in lemma.dependencies:\n",
    "                if dep in self.lemmas:\n",
    "                    adj[dep].append(lemma.id)\n",
    "                    in_deg[lemma.id] += 1\n",
    "        \n",
    "        # Start with nodes having no dependencies\n",
    "        queue = [lid for lid, deg in in_deg.items() if deg == 0]\n",
    "        result = []\n",
    "        \n",
    "        while queue:\n",
    "            lid = queue.pop(0)\n",
    "            result.append(lid)\n",
    "            \n",
    "            for neighbor in adj[lid]:\n",
    "                in_deg[neighbor] -= 1\n",
    "                if in_deg[neighbor] == 0:\n",
    "                    queue.append(neighbor)\n",
    "        \n",
    "        if len(result) != len(self.lemmas):\n",
    "            # Fallback: return in ID order\n",
    "            return sorted(self.lemmas.keys())\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_lemma_summary(self) -> str:\n",
    "        \"\"\"Create formatted summary of all lemmas\"\"\"\n",
    "        summary_lines = []\n",
    "        for lemma_id in self.get_dependency_order():\n",
    "            lemma = self.lemmas[lemma_id]\n",
    "            summary_lines.append(lemma.to_summary())\n",
    "        return \"\\n\".join(summary_lines)\n",
    "\n",
    "@dataclass\n",
    "class SolutionResult:\n",
    "    problem: str\n",
    "    classification: ProblemClassification\n",
    "    answer: Optional[int] = None\n",
    "    success: bool = False\n",
    "    time_taken: float = 0.0\n",
    "    method: str = 'unknown'\n",
    "    confidence: float = 0.0\n",
    "    solution_text: str = ''\n",
    "\n",
    "print('Data structures defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "688dce28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.670804Z",
     "iopub.status.busy": "2026-02-03T02:43:39.670651Z",
     "iopub.status.idle": "2026-02-03T02:43:39.677897Z",
     "shell.execute_reply": "2026-02-03T02:43:39.677504Z"
    },
    "papermill": {
     "duration": 0.013888,
     "end_time": "2026-02-03T02:43:39.678715",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.664827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sandbox defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# JUPYTER SANDBOX\n",
    "# ============================================================\n",
    "\n",
    "from jupyter_client import KernelManager\n",
    "\n",
    "class ALGSandbox:\n",
    "    _port_lock = threading.Lock()\n",
    "    _next_port = 50000\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_next_ports(cls, count=5):\n",
    "        with cls._port_lock:\n",
    "            ports = list(range(cls._next_port, cls._next_port + count))\n",
    "            cls._next_port += count\n",
    "            return ports\n",
    "    \n",
    "    def __init__(self, timeout=30.0):\n",
    "        self.timeout = timeout\n",
    "        ports = self._get_next_ports(5)\n",
    "        env = os.environ.copy()\n",
    "        env['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "        env['PYTHONWARNINGS'] = 'ignore'\n",
    "        \n",
    "        self._km = KernelManager()\n",
    "        self._km.shell_port = ports[0]\n",
    "        self._km.iopub_port = ports[1]\n",
    "        self._km.stdin_port = ports[2]\n",
    "        self._km.hb_port = ports[3]\n",
    "        self._km.control_port = ports[4]\n",
    "        \n",
    "        self._km.start_kernel(env=env)\n",
    "        self._client = self._km.blocking_client()\n",
    "        self._client.start_channels()\n",
    "        self._client.wait_for_ready(timeout=30)\n",
    "        \n",
    "        init_code = '''import math\n",
    "import sympy as sp\n",
    "import itertools\n",
    "import numpy as np'''\n",
    "        self.execute(init_code)\n",
    "    \n",
    "    def execute(self, code, timeout=None):\n",
    "        timeout = timeout or self.timeout\n",
    "        msg_id = self._client.execute(code, store_history=False)\n",
    "        stdout, stderr = [], []\n",
    "        start = time.time()\n",
    "        while True:\n",
    "            if time.time() - start > timeout:\n",
    "                self._km.interrupt_kernel()\n",
    "                return {'success': False, 'output': '', 'error': 'Timeout'}\n",
    "            try:\n",
    "                msg = self._client.get_iopub_msg(timeout=1.0)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if msg.get('parent_header', {}).get('msg_id') != msg_id:\n",
    "                continue\n",
    "            msg_type = msg.get('msg_type')\n",
    "            content = msg.get('content', {})\n",
    "            if msg_type == 'stream':\n",
    "                text = content.get('text', '')\n",
    "                if content.get('name') == 'stdout':\n",
    "                    stdout.append(text)\n",
    "                else:\n",
    "                    stderr.append(text)\n",
    "            elif msg_type == 'error':\n",
    "                stderr.append('\\n'.join(content.get('traceback', [])))\n",
    "            elif msg_type == 'status' and content.get('execution_state') == 'idle':\n",
    "                break\n",
    "        stdout, stderr = ''.join(stdout), ''.join(stderr)\n",
    "        if stderr:\n",
    "            return {'success': False, 'output': stdout, 'error': stderr}\n",
    "        return {'success': True, 'output': stdout.strip(), 'error': None}\n",
    "    \n",
    "    def close(self):\n",
    "        if self._client:\n",
    "            self._client.stop_channels()\n",
    "        if self._km:\n",
    "            self._km.shutdown_kernel(now=True)\n",
    "\n",
    "print('Sandbox defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b89e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.689799Z",
     "iopub.status.busy": "2026-02-03T02:43:39.689647Z",
     "iopub.status.idle": "2026-02-03T02:43:39.694939Z",
     "shell.execute_reply": "2026-02-03T02:43:39.694565Z"
    },
    "papermill": {
     "duration": 0.01181,
     "end_time": "2026-02-03T02:43:39.695698",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.683888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM interface defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LLM INTERFACE\n",
    "# ============================================================\n",
    "\n",
    "class LLMInterface:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.base_url = f'http://0.0.0.0:{cfg.server_port}/v1'\n",
    "        self.api_key = 'sk-local'\n",
    "        self.client = None\n",
    "        self.encoding = None\n",
    "        self.stop_token_ids = None\n",
    "    \n",
    "    def initialize(self):\n",
    "        print('[LLM] Connecting to vLLM server...', flush=True)\n",
    "        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key, timeout=300)\n",
    "        self.encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n",
    "        self.stop_token_ids = self.encoding.stop_tokens_for_assistant_actions()\n",
    "        print('[LLM] Connected successfully', flush=True)\n",
    "    \n",
    "    def generate(self, system_prompt, user_prompt, temperature=None, max_tokens=None):\n",
    "        temp = temperature or self.cfg.temperature\n",
    "        max_tok = max_tokens or self.cfg.max_tokens_per_turn\n",
    "        print(f'[LLM] Generating (temp={temp}, max_tokens={max_tok})...', flush=True)\n",
    "        if not self.client:\n",
    "            raise RuntimeError('LLM client not initialized!')\n",
    "        if not self.encoding:\n",
    "            raise RuntimeError('Encoding not initialized!')\n",
    "        \n",
    "        system_content = (SystemContent.new()\n",
    "            .with_model_identity(system_prompt)\n",
    "            .with_reasoning_effort(reasoning_effort=ReasoningEffort.HIGH))\n",
    "        system_msg = Message.from_role_and_content(Role.SYSTEM, system_content)\n",
    "        user_msg = Message.from_role_and_content(Role.USER, TextContent(text=user_prompt))\n",
    "        conversation = Conversation.from_messages([system_msg, user_msg])\n",
    "        prompt_ids = self.encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)\n",
    "        \n",
    "        response = self.client.completions.create(\n",
    "            model=self.cfg.served_model_name,\n",
    "            temperature=temp,\n",
    "            max_tokens=max_tok,\n",
    "            prompt=prompt_ids,\n",
    "            stop=None)\n",
    "        \n",
    "        result = response.choices[0].text\n",
    "        print(f'[LLM] Generated {len(result)} chars', flush=True)\n",
    "        return result\n",
    "\n",
    "print('LLM interface defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a8fae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.706658Z",
     "iopub.status.busy": "2026-02-03T02:43:39.706497Z",
     "iopub.status.idle": "2026-02-03T02:43:39.715083Z",
     "shell.execute_reply": "2026-02-03T02:43:39.714728Z"
    },
    "papermill": {
     "duration": 0.015092,
     "end_time": "2026-02-03T02:43:39.715848",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.700756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing utilities defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# JSON PARSING UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "class JSONParser:\n",
    "    @staticmethod\n",
    "    def parse_json_response(text: str, fallback=None):\n",
    "        \"\"\"Try to parse JSON from text, with fallback\"\"\"\n",
    "        if not text:\n",
    "            return fallback\n",
    "        \n",
    "        # Try to extract JSON from text\n",
    "        try:\n",
    "            # Look for JSON pattern\n",
    "            json_pattern = r'\\{.*\\}'\n",
    "            match = re.search(json_pattern, text, re.DOTALL)\n",
    "            if match:\n",
    "                json_str = match.group(0)\n",
    "                return json.loads(json_str)\n",
    "            \n",
    "            # If no match, try parsing entire text\n",
    "            return json.loads(text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[WARNING] JSON parse error: {e}\")\n",
    "            print(f\"[DEBUG] Text snippet: {text[:200]}...\")\n",
    "            return fallback\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_classification(text: str) -> ProblemClassification:\n",
    "        \"\"\"Parse classification from JSON response\"\"\"\n",
    "        data = JSONParser.parse_json_response(text)\n",
    "        if not data:\n",
    "            return ProblemClassification(\n",
    "                topic='algebra',\n",
    "                complexity='medium',\n",
    "                confidence=0.5\n",
    "            )\n",
    "        \n",
    "        return ProblemClassification(\n",
    "            topic=data.get('topic', 'algebra'),\n",
    "            complexity=data.get('complexity', 'medium'),\n",
    "            key_techniques=data.get('key_techniques', []),\n",
    "            estimated_lemmas=data.get('estimated_lemmas', 4),\n",
    "            reasoning=data.get('reasoning', ''),\n",
    "            confidence=data.get('confidence', 0.5)\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_lemma_graph(text: str, problem: str, classification: ProblemClassification) -> LemmaGraph:\n",
    "        \"\"\"Parse lemma graph from JSON response\"\"\"\n",
    "        data = JSONParser.parse_json_response(text)\n",
    "        if not data:\n",
    "            return LemmaGraph(problem, classification)\n",
    "        \n",
    "        graph = LemmaGraph(\n",
    "            problem=problem,\n",
    "            classification=classification,\n",
    "            graph_strategy=data.get('graph_strategy', '')\n",
    "        )\n",
    "        \n",
    "        # Parse lemmas\n",
    "        for lemma_data in data.get('lemmas', []):\n",
    "            lemma = Lemma(\n",
    "                id=lemma_data.get('id', 'L?'),\n",
    "                statement=lemma_data.get('statement', ''),\n",
    "                lemma_type=lemma_data.get('type', 'structural'),\n",
    "                dependencies=lemma_data.get('dependencies', []),\n",
    "                purpose=lemma_data.get('purpose', ''),\n",
    "                verification_strategy=lemma_data.get('verification_strategy', ''),\n",
    "                domain_hint=lemma_data.get('domain_hint', '')\n",
    "            )\n",
    "            graph.lemmas[lemma.id] = lemma\n",
    "        \n",
    "        # Parse final lemma\n",
    "        final_data = data.get('final_lemma')\n",
    "        if final_data:\n",
    "            graph.final_lemma = Lemma(\n",
    "                id=final_data.get('id', 'FINAL'),\n",
    "                statement=final_data.get('statement', ''),\n",
    "                lemma_type=final_data.get('type', 'synthesis'),\n",
    "                dependencies=final_data.get('dependencies', []),\n",
    "                purpose=final_data.get('purpose', '')\n",
    "            )\n",
    "            graph.lemmas['FINAL'] = graph.final_lemma\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_lemma_proof(text: str) -> Dict:\n",
    "        \"\"\"Parse lemma proof from JSON response\"\"\"\n",
    "        data = JSONParser.parse_json_response(text)\n",
    "        if not data:\n",
    "            return {\n",
    "                'proof': '',\n",
    "                'verification_code': '',\n",
    "                'verification_explanation': '',\n",
    "                'confidence': 0.5,\n",
    "                'key_insights': []\n",
    "            }\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_solution(text: str) -> Dict:\n",
    "        \"\"\"Parse solution from JSON response\"\"\"\n",
    "        data = JSONParser.parse_json_response(text)\n",
    "        if not data:\n",
    "            return {\n",
    "                'answer': 0,\n",
    "                'confidence': 0.0,\n",
    "                'step_by_step_solution': '',\n",
    "                'verification_checks': []\n",
    "            }\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_answer(text):\n",
    "        \"\"\"Extract boxed answer from text\"\"\"\n",
    "        matches = re.findall(r'boxed\\s*\\{\\s*([0-9,]+)\\s*\\}', text)\n",
    "        if matches:\n",
    "            try:\n",
    "                val = int(matches[-1].replace(',', ''))\n",
    "                if 0 <= val <= 99999: return val\n",
    "            except: pass\n",
    "        return None\n",
    "\n",
    "print('JSON parsing utilities defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94228a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.726716Z",
     "iopub.status.busy": "2026-02-03T02:43:39.726463Z",
     "iopub.status.idle": "2026-02-03T02:43:39.741222Z",
     "shell.execute_reply": "2026-02-03T02:43:39.740841Z"
    },
    "papermill": {
     "duration": 0.021377,
     "end_time": "2026-02-03T02:43:39.741997",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.720620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALG Solver with lemma logic defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPROVED ALG SOLVER WITH LEMMA LOGIC\n",
    "# ============================================================\n",
    "\n",
    "class ALGSolver:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.llm = LLMInterface(cfg)\n",
    "        self.sandbox = None\n",
    "        self.parser = JSONParser()\n",
    "    \n",
    "    def initialize(self):\n",
    "        print('[ALG] Initializing...')\n",
    "        sys.stdout.flush()\n",
    "        self.sandbox = ALGSandbox(timeout=self.cfg.sandbox_timeout)\n",
    "        self.llm.initialize()\n",
    "        print('[ALG] Ready')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    def get_domain_context(self, topic):\n",
    "        \"\"\"Get formatted domain context for prompts\"\"\"\n",
    "        domain_info = CFG.DOMAIN_KNOWLEDGE.get(topic, CFG.DOMAIN_KNOWLEDGE['algebra'])\n",
    "        \n",
    "        context = f\"Topic: {topic}\\n\"\n",
    "        context += f\"Description: {domain_info['description']}\\n\\n\"\n",
    "        context += \"Common Techniques:\\n\"\n",
    "        for i, technique in enumerate(domain_info['common_techniques'][:5], 1):\n",
    "            context += f\"{i}. {technique}\\n\"\n",
    "        \n",
    "        context += \"\\nCommon Patterns:\\n\"\n",
    "        for i, pattern in enumerate(domain_info['common_patterns'][:3], 1):\n",
    "            context += f\"{i}. {pattern}\\n\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def get_imo_strategies(self):\n",
    "        \"\"\"Get formatted IMO strategies\"\"\"\n",
    "        strategies = \"IMO Problem Solving Strategies:\\n\"\n",
    "        for i, strategy in enumerate(CFG.IMO_STRATEGIES[:5], 1):\n",
    "            strategies += f\"{i}. {strategy}\\n\"\n",
    "        return strategies\n",
    "    \n",
    "    def classify_problem(self, problem):\n",
    "        print('\\n=== PHASE 1: PROBLEM CLASSIFICATION ===')\n",
    "        \n",
    "        # Get general domain context for classification\n",
    "        domain_context = \"Available Domains:\\n\"\n",
    "        for topic, info in CFG.DOMAIN_KNOWLEDGE.items():\n",
    "            domain_context += f\"- {topic}: {info['description'][:100]}...\\n\"\n",
    "        \n",
    "        prompt = CLASSIFICATION_PROMPT.format(\n",
    "            problem=problem,\n",
    "            domain_context=domain_context\n",
    "        )\n",
    "        \n",
    "        response = self.llm.generate(\n",
    "            system_prompt=\"You are an expert IMO problem classifier. Output ONLY valid JSON.\",\n",
    "            user_prompt=prompt,\n",
    "            temperature=0.3,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        print(f'[ALG] Classification response: {response[:200]}...')\n",
    "        \n",
    "        classification = self.parser.parse_classification(response)\n",
    "        \n",
    "        print(f'[ALG] Topic: {classification.topic}')\n",
    "        print(f'[ALG] Complexity: {classification.complexity}')\n",
    "        print(f'[ALG] Estimated lemmas: {classification.estimated_lemmas}')\n",
    "        print(f'[ALG] Confidence: {classification.confidence:.2f}')\n",
    "        print(f'[ALG] Budget: {classification.get_time_budget()}s')\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def build_lemma_graph(self, problem, classification):\n",
    "        print('\\n=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===')\n",
    "        \n",
    "        domain_knowledge = self.get_domain_context(classification.topic)\n",
    "        imo_strategies = self.get_imo_strategies()\n",
    "        \n",
    "        prompt = LEMMA_GRAPH_PROMPT.format(\n",
    "            problem=problem,\n",
    "            topic=classification.topic,\n",
    "            complexity=classification.complexity,\n",
    "            estimated_lemmas=classification.estimated_lemmas,\n",
    "            domain_knowledge=domain_knowledge,\n",
    "            imo_strategies=imo_strategies\n",
    "        )\n",
    "        \n",
    "        response = self.llm.generate(\n",
    "            system_prompt=\"You are an IMO Gold Medalist decomposing problems into lemma graphs. Output ONLY valid JSON.\",\n",
    "            user_prompt=prompt,\n",
    "            temperature=0.5,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        print(f'[ALG] Lemma graph response: {response[:300]}...')\n",
    "        \n",
    "        graph = self.parser.parse_lemma_graph(response, problem, classification)\n",
    "        \n",
    "        print(f'[ALG] Graph created: {len(graph.lemmas)} lemmas + final')\n",
    "        print(f'[ALG] Dependencies: {graph.get_dependency_order()}')\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    def verify_lemma(self, lemma, problem, classification):\n",
    "        \"\"\"Verify a single lemma with proof and code execution\"\"\"\n",
    "        print(f'[ALG] Verifying lemma {lemma.id}: {lemma.lemma_type}')\n",
    "        \n",
    "        domain_info = classification.get_domain_info()\n",
    "        domain_techniques = \"\\n\".join(domain_info.get('common_techniques', [])[:3])\n",
    "        \n",
    "        prompt = LEMMA_PROOF_PROMPT.format(\n",
    "            problem=problem,\n",
    "            lemma_id=lemma.id,\n",
    "            lemma_statement=lemma.statement,\n",
    "            lemma_type=lemma.lemma_type,\n",
    "            purpose=lemma.purpose,\n",
    "            topic=classification.topic,\n",
    "            domain_techniques=domain_techniques\n",
    "        )\n",
    "        \n",
    "        response = self.llm.generate(\n",
    "            system_prompt=\"You are a mathematical proof assistant. Output ONLY valid JSON.\",\n",
    "            user_prompt=prompt,\n",
    "            temperature=0.3,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        \n",
    "        proof_data = self.parser.parse_lemma_proof(response)\n",
    "        \n",
    "        lemma.proof = proof_data.get('proof', '')\n",
    "        lemma.verification_code = proof_data.get('verification_code', '')\n",
    "        lemma.confidence = proof_data.get('confidence', 0.5)\n",
    "        \n",
    "        # Try to execute verification code if provided\n",
    "        if lemma.verification_code and self.sandbox:\n",
    "            print(f'[ALG] Executing verification code for {lemma.id}')\n",
    "            result = self.sandbox.execute(lemma.verification_code)\n",
    "            lemma.execution_result = f\"Output: {result.get('output', '')}\\nError: {result.get('error', '')}\"\n",
    "            lemma.verified = result.get('success', False)\n",
    "            \n",
    "            if lemma.verified:\n",
    "                print(f'[ALG]  Lemma {lemma.id} verified')\n",
    "            else:\n",
    "                print(f'[ALG]  Lemma {lemma.id} verification failed')\n",
    "        else:\n",
    "            # For theoretical lemmas, assume verified if proof seems reasonable\n",
    "            lemma.verified = len(lemma.proof) > 100  # Simple heuristic\n",
    "            print(f'[ALG] {\"\" if lemma.verified else \"\"} Lemma {lemma.id} (theoretical)')\n",
    "        \n",
    "        return lemma.verified\n",
    "    \n",
    "    def solve_via_lemmas(self, problem, classification, graph):\n",
    "        \"\"\"Solve problem using lemma graph approach\"\"\"\n",
    "        print('\\n=== PHASE 3: LEMMA VERIFICATION ===')\n",
    "        \n",
    "        # Verify lemmas in dependency order\n",
    "        verified_count = 0\n",
    "        lemma_order = graph.get_dependency_order()\n",
    "        \n",
    "        for lemma_id in lemma_order:\n",
    "            if lemma_id == 'FINAL':\n",
    "                continue\n",
    "                \n",
    "            lemma = graph.lemmas[lemma_id]\n",
    "            if self.verify_lemma(lemma, problem, classification):\n",
    "                verified_count += 1\n",
    "            \n",
    "            # Check time budget\n",
    "            # (Time check would go here)\n",
    "        \n",
    "        print(f'[ALG] Verified {verified_count}/{len(graph.lemmas)} lemmas')\n",
    "        \n",
    "        # Generate solution using verified lemmas\n",
    "        print('\\n=== PHASE 4: SOLUTION SYNTHESIS ===')\n",
    "        \n",
    "        lemmas_summary = graph.get_lemma_summary()\n",
    "        domain_knowledge = self.get_domain_context(classification.topic)\n",
    "        \n",
    "        prompt = SOLUTION_PROMPT.format(\n",
    "            problem=problem,\n",
    "            topic=classification.topic,\n",
    "            domain_knowledge=domain_knowledge,\n",
    "            lemmas_summary=lemmas_summary\n",
    "        )\n",
    "        \n",
    "        response = self.llm.generate(\n",
    "            system_prompt=\"You are an IMO Gold Medalist solving problems. Output ONLY valid JSON.\",\n",
    "            user_prompt=prompt,\n",
    "            temperature=0.3,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        solution_data = self.parser.parse_solution(response)\n",
    "        \n",
    "        return solution_data\n",
    "    \n",
    "    def solve_directly(self, problem, classification):\n",
    "        \"\"\"Fallback: Solve problem directly without lemma graph\"\"\"\n",
    "        print('\\n=== DIRECT SOLUTION (FALLBACK) ===')\n",
    "        \n",
    "        domain_knowledge = self.get_domain_context(classification.topic)\n",
    "        imo_strategies = self.get_imo_strategies()\n",
    "        \n",
    "        prompt = DIRECT_SOLUTION_PROMPT.format(\n",
    "            problem=problem,\n",
    "            topic=classification.topic,\n",
    "            domain_knowledge=domain_knowledge,\n",
    "            imo_strategies=imo_strategies\n",
    "        )\n",
    "        \n",
    "        response = self.llm.generate(\n",
    "            system_prompt=\"You are an IMO Gold Medalist solving problems. Output ONLY valid JSON.\",\n",
    "            user_prompt=prompt,\n",
    "            temperature=0.3,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        solution_data = self.parser.parse_solution(response)\n",
    "        return solution_data\n",
    "    \n",
    "    def solve(self, problem):\n",
    "        \"\"\"Main entry point for solving a problem\"\"\"\n",
    "        start_time = time.time()\n",
    "        print('\\n' + '='*60)\n",
    "        print(f'PROBLEM: {problem[:100]}...')\n",
    "        print('='*60)\n",
    "        \n",
    "        try:\n",
    "            # Phase 1: Classification\n",
    "            classification = self.classify_problem(problem)\n",
    "            time_budget = classification.get_time_budget()\n",
    "            print(f'[ALG] Time budget: {time_budget}s')\n",
    "            \n",
    "            # Phase 2 & 3: Build and verify lemma graph\n",
    "            graph = self.build_lemma_graph(problem, classification)\n",
    "            \n",
    "            # Check if we have a valid lemma graph\n",
    "            if len(graph.lemmas) > 0:\n",
    "                solution_data = self.solve_via_lemmas(problem, classification, graph)\n",
    "                method = 'lemma_graph'\n",
    "            else:\n",
    "                # Fallback to direct solution\n",
    "                solution_data = self.solve_directly(problem, classification)\n",
    "                method = 'direct'\n",
    "            \n",
    "            # Extract answer\n",
    "            answer = solution_data.get('answer', 0)\n",
    "            confidence = solution_data.get('confidence', 0.0)\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'[ALG] Answer: {answer}, Confidence: {confidence:.2f}, Time: {elapsed:.1f}s')\n",
    "            \n",
    "            return SolutionResult(\n",
    "                problem=problem,\n",
    "                classification=classification,\n",
    "                answer=answer,\n",
    "                success=answer is not None and answer != 0,\n",
    "                time_taken=elapsed,\n",
    "                method=method,\n",
    "                confidence=confidence,\n",
    "                solution_text=solution_data.get('step_by_step_solution', '')\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'[ALG] ERROR: {e}')\n",
    "            traceback.print_exc()\n",
    "            return SolutionResult(\n",
    "                problem=problem,\n",
    "                classification=ProblemClassification('unknown', 'medium'),\n",
    "                answer=0,\n",
    "                success=False,\n",
    "                time_taken=time.time() - start_time,\n",
    "                method='error'\n",
    "            )\n",
    "\n",
    "print('ALG Solver with lemma logic defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f368537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.753127Z",
     "iopub.status.busy": "2026-02-03T02:43:39.752683Z",
     "iopub.status.idle": "2026-02-03T02:43:39.758725Z",
     "shell.execute_reply": "2026-02-03T02:43:39.758325Z"
    },
    "papermill": {
     "duration": 0.012733,
     "end_time": "2026-02-03T02:43:39.759542",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.746809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server manager defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SERVER MANAGER\n",
    "# ============================================================\n",
    "\n",
    "class ServerManager:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.server_process = None\n",
    "        self.log_file = None\n",
    "    \n",
    "    def preload_model(self):\n",
    "        print(f'Loading model from {self.cfg.model_path}...')\n",
    "        start = time.time()\n",
    "        files = []\n",
    "        for root, _, fs in os.walk(self.cfg.model_path):\n",
    "            for f in fs:\n",
    "                path = os.path.join(root, f)\n",
    "                if os.path.isfile(path): files.append(path)\n",
    "        def read_file(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                while f.read(1024 * 1024 * 1024): pass\n",
    "        with ThreadPoolExecutor(max_workers=16) as exe:\n",
    "            list(exe.map(read_file, files))\n",
    "        print(f'Loaded {len(files)} files in {time.time()-start:.1f}s\\n')\n",
    "    \n",
    "    def start_server(self):\n",
    "        cmd = [sys.executable, '-m', 'vllm.entrypoints.openai.api_server',\n",
    "               '--model', self.cfg.model_path,\n",
    "               '--served-model-name', self.cfg.served_model_name,\n",
    "               '--host', '0.0.0.0', '--port', str(self.cfg.server_port),\n",
    "               '--tensor-parallel-size', '1',\n",
    "               '--max-model-len', str(self.cfg.context_tokens),\n",
    "               '--gpu-memory-utilization', str(self.cfg.gpu_memory_utilization),\n",
    "               '--kv-cache-dtype', self.cfg.kv_cache_dtype,\n",
    "               '--disable-log-stats', '--enable-prefix-caching']\n",
    "        self.log_file = open('vllm_server.log', 'w')\n",
    "        return subprocess.Popen(cmd, stdout=self.log_file, stderr=subprocess.STDOUT)\n",
    "    \n",
    "    def wait_for_server(self, client, timeout=180):\n",
    "        print('Waiting for vLLM server...')\n",
    "        start = time.time()\n",
    "        for _ in range(timeout):\n",
    "            if self.server_process.poll() is not None:\n",
    "                raise RuntimeError('Server died')\n",
    "            try:\n",
    "                client.models.list()\n",
    "                print(f'Server ready in {time.time()-start:.1f}s\\n')\n",
    "                return\n",
    "            except: time.sleep(1)\n",
    "        raise RuntimeError('Server timeout')\n",
    "    \n",
    "    def stop_server(self):\n",
    "        if self.server_process: self.server_process.terminate(); self.server_process.wait()\n",
    "        if self.log_file: self.log_file.close()\n",
    "\n",
    "print('Server manager defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6272d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.771029Z",
     "iopub.status.busy": "2026-02-03T02:43:39.770685Z",
     "iopub.status.idle": "2026-02-03T02:43:39.774620Z",
     "shell.execute_reply": "2026-02-03T02:43:39.774243Z"
    },
    "papermill": {
     "duration": 0.010602,
     "end_time": "2026-02-03T02:43:39.775421",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.764819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KAGGLE INTERFACE\n",
    "# ============================================================\n",
    "\n",
    "_solver = None\n",
    "_server_manager = None\n",
    "\n",
    "def initialize_solver():\n",
    "    global _solver, _server_manager\n",
    "    if _solver: return _solver\n",
    "    print('Initializing...')\n",
    "    _server_manager = ServerManager(CFG)\n",
    "    _server_manager.preload_model()\n",
    "    _server_manager.server_process = _server_manager.start_server()\n",
    "    _solver = ALGSolver(CFG)\n",
    "    temp_client = OpenAI(base_url=f'http://0.0.0.0:{CFG.server_port}/v1', api_key='sk-local')\n",
    "    _server_manager.wait_for_server(temp_client, CFG.server_timeout)\n",
    "    _solver.initialize()\n",
    "    return _solver\n",
    "\n",
    "def predict(id_, question):\n",
    "    id_value = id_.item(0)\n",
    "    question_text = question.item(0)\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'PROBLEM ID: {id_value}')\n",
    "    print('='*60)\n",
    "    solver = initialize_solver()\n",
    "    result = solver.solve(question_text)\n",
    "    answer = result.answer if result.answer else 0\n",
    "    print(f'\\nSUBMITTING: {answer}')\n",
    "    return pl.DataFrame({'id': id_value, 'answer': int(answer)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7099c06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T02:43:39.786393Z",
     "iopub.status.busy": "2026-02-03T02:43:39.786243Z",
     "iopub.status.idle": "2026-02-03T02:51:18.418974Z",
     "shell.execute_reply": "2026-02-03T02:51:18.418394Z"
    },
    "papermill": {
     "duration": 458.639346,
     "end_time": "2026-02-03T02:51:18.419924",
     "exception": false,
     "start_time": "2026-02-03T02:43:39.780578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using reference.csv: 10 problems\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 92ba6a\n",
      "============================================================\n",
      "Initializing...\n",
      "Loading model from /kaggle/input/gpt-oss-120b/transformers/default/1...\n",
      "Loaded 26 files in 80.0s\n",
      "\n",
      "Waiting for vLLM server...\n",
      "Server ready in 135.4s\n",
      "\n",
      "[ALG] Initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ColabKernelApp] WARNING | Eventloop or matplotlib integration failed. Is matplotlib installed?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM] Connecting to vLLM server...\n",
      "[LLM] Connected successfully\n",
      "[ALG] Ready\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Alice and Bob are each holding some integer number of sweets. Alice says to Bob: ``If we each added ...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 2074 chars\n",
      "[ALG] Classification response: analysisWe need to parse the problem: \"Alice and Bob are each holding some integer number of sweets. Alice says to Bob: ``If we each added the number of sweets we're holding to our (positive integer) ...\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to parse the problem: \"Alice and Bob are each holding some integer number of sweets. Alice says to Bob: ``If we each added the number of sweets we're holding to our (positive integer) ...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 5235 chars\n",
      "[ALG] Lemma graph response: analysisWe need to decompose the problem into lemmas. The problem: Alice and Bob each hold some integer number of sweets. Let A_s = a (Alice sweets), B_s = b (Bob sweets), both nonnegative integers? \"some integer number of sweets\" could be positive integer? Might be nonnegative integer (including ze...\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to decompose the problem into lemmas. The problem: Alice and Bob each hold some integer number of sweets. Let A_s = a (Alice sweets), B_s = b (Bob sweets), both nonnegative integers? \"...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 5974 chars\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to solve a puzzle: Alice and Bob each hold some integer number of sweets. Let A_s = number of sweets Alice has, B_s = number of sweets Bob has. Let a = Alice's age (positive integer), ...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.2s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: dd7f5e\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Let $\\mathcal{F}$ be the set of functions $\\alpha \\colon \\mathbb{Z}\\to \\mathbb{Z}$ for which there a...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 1647 chars\n",
      "[ALG] Classification response: analysisWe need to analyze the problem: Count the number of shifty functions    (finite support) with support within [0,8] (since (m)=0 for m<0 and m>8). There exists    and distinct integers k...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to analyze the problem: Count the number of shifty functions    (finite support) with support within [0,8] (since (m)=0 for m<0 and m>8). There exists    and distinct integers k...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 6854 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a JSON with lemmas and final lemma and graph strategy. The problem asks: How many shifty functions are there in F? We need to count functions  with support in [0,8] (since (m)=0 for m<0 and m>8). Also there exists  and distinct integers k,l such that for all n, S_n() ...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a JSON with lemmas and final lemma and graph strategy. The problem asks: How many shifty functions are there in F? We need to count functions  with support in [0,8] (since ...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 6653 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve the problem: count the number of shifty functions    (finite support functions ) satisfying:\n",
      "\n",
      "1. (m)=0 for all m<0 and m>8. So  is supported within {0,1,...,8}.\n",
      "\n",
      "2. Th...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.2s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 42d360\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: On a blackboard, Ken starts off by writing a positive integer $n$ and then applies the following mov...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 1966 chars\n",
      "[ALG] Classification response: analysisWe need to classify the problem: It's about a process where you replace a number m by the sum of its digits in some base b (2  b  m). The process continues until reaching 1. For each startin...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to classify the problem: It's about a process where you replace a number m by the sum of its digits in some base b (2  b  m). The process continues until reaching 1. For each startin...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 7539 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a lemma graph for the problem. The problem: Ken writes a positive integer n and repeatedly replaces m with the sum of its digits in some base b (2  b  m). The process ends when m=1. For each n, the number of moves depends on choices of bases at each step. We need to cons...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a lemma graph for the problem. The problem: Ken writes a positive integer n and repeatedly replaces m with the sum of its digits in some base b (2  b  m). The process ends...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 6172 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve a problem: For each starting integer n (1  n  10^{10^5}), Ken performs moves: given current m, choose a base b (2  b  m), write m in base b, sum its digits (i.e., sum of c...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.1s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 9c1c5f\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Let $f \\colon \\mathbb{Z}_{\\geq 1} \\to \\mathbb{Z}_{\\geq 1}$ be a function such that for all positive ...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 1747 chars\n",
      "[ALG] Classification response: analysisWe need to analyze the problem: find possible values of f(2024) given functional equation f(m)+f(n)=f(m+n+mn) for all positive integers m,n. Also constraint: f(n)  1000 for all n  1000. We n...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to analyze the problem: find possible values of f(2024) given functional equation f(m)+f(n)=f(m+n+mn) for all positive integers m,n. Also constraint: f(n)  1000 for all n  1000. We n...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 6053 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a JSON with lemmas (target count 4). Provide a lemma graph for solving this functional equation problem.\n",
      "\n",
      "First we need to understand the problem: We have f: positive integers to positive integers satisfying f(m) + f(n) = f(m + n + mn). This is reminiscent of the identity ...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a JSON with lemmas (target count 4). Provide a lemma graph for solving this functional equation problem.\n",
      "\n",
      "First we need to understand the problem: We have f: positive intege...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 6190 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve functional equation f: positive integers -> positive integers satisfying f(m)+f(n)=f(m+n+mn). This is reminiscent of the function f(n)=c*(n+1) maybe? Let's examine.\n",
      "\n",
      "Lets def...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.1s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 641659\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Let $ABC$ be a triangle with $AB \\neq AC$, circumcircle $\\Omega$, and incircle $\\omega$. Let the con...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 2220 chars\n",
      "[ALG] Classification response: analysisWe need to analyze the problem: It's a geometry problem with incircle, circumcircle, contact points, some points K, K', N, T, and a condition that BD = F_n, CD = F_{n+1} (Fibonacci numbers). A...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to analyze the problem: It's a geometry problem with incircle, circumcircle, contact points, some points K, K', N, T, and a condition that BD = F_n, CD = F_{n+1} (Fibonacci numbers). A...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 7732 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a lemma graph for the given problem. The problem is quite complex: geometry with incircle, circumcircle, contact points, a certain cyclic condition, a ratio expression, and a Fibonacci condition. Then we need to define a_n as maximum of a ratio across all n-tastic triangle...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a lemma graph for the given problem. The problem is quite complex: geometry with incircle, circumcircle, contact points, a certain cyclic condition, a ratio expression, and ...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 7692 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve a fairly complicated geometry problem with a number theory/sequence twist. The problem defines an \"n-tastic\" triangle with BD = F_n, CD = F_{n+1}, and KNK'B cyclic. Then for e...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.2s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 0e644e\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Let $ABC$ be an acute-angled triangle with integer side lengths and $AB<AC$. Points $D$ and $E$ lie ...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 2219 chars\n",
      "[ALG] Classification response: analysisWe need to classify the problem: It's a geometry problem with integer side lengths, acute triangle, constraints about points D, E, circles, etc. Need to find minimal perimeter triangle satisfy...\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to classify the problem: It's a geometry problem with integer side lengths, acute triangle, constraints about points D, E, circles, etc. Need to find minimal perimeter triangle satisfy...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 7437 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a JSON containing lemmas (target count 4) that decompose the problem. The problem: acute-angled triangle ABC with integer sides, AB<AC, points D on BC, E on AC such that AD=AE=AB. DE intersects AB at X. Circles BXD and CED intersect again at Y ( D). Suppose Y lies on line...\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a JSON containing lemmas (target count 4) that decompose the problem. The problem: acute-angled triangle ABC with integer sides, AB<AC, points D on BC, E on AC such that AD=...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 5673 chars\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to solve a geometry problem: acute triangle ABC with integer side lengths, AB < AC. Points D on BC, E on AC such that AD = AE = AB. So AD = AE = c (since AB = c). So D is on BC such th...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.1s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 26de63\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Define a function $f \\colon \\mathbb{Z}_{\\geq 1} \\to \\mathbb{Z}_{\\geq 1}$ by\n",
      "\\begin{equation*}\n",
      "    f(...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 1566 chars\n",
      "[ALG] Classification response: analysisWe need to parse the problem: define f: Z_{>=1} -> Z_{>=1} by\n",
      "\n",
      "f(n) = sum_{i=1}^n sum_{j=1}^n j^{1024} floor(1/j + (n-i)/n).\n",
      "\n",
      "Let M = 2*3*5*7*11*13 = product of first six primes up to 13. Comp...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to parse the problem: define f: Z_{>=1} -> Z_{>=1} by\n",
      "\n",
      "f(n) = sum_{i=1}^n sum_{j=1}^n j^{1024} floor(1/j + (n-i)/n).\n",
      "\n",
      "Let M = 2*3*5*7*11*13 = product of first six primes up to 13. Comp...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 5091 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a lemma graph for the problem. Not solve fully, but decompose into lemmas. The problem: given f(n) = sum_{i=1}^n sum_{j=1}^n j^{1024} floor(1/j + (n-i)/n). Compute N = f(M^15) - f(M^15 - 1). Find largest k such that 2^k divides N. Then compute remainder of 2^k mod 5^7. So ...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a lemma graph for the problem. Not solve fully, but decompose into lemmas. The problem: given f(n) = sum_{i=1}^n sum_{j=1}^n j^{1024} floor(1/j + (n-i)/n). Compute N = f(M^1...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 4641 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve the problem: define f: positive integers to positive integers by\n",
      "\n",
      "f(n) = sum_{i=1}^n sum_{j=1}^n j^{1024} floor(1/j + (n-i)/n).\n",
      "\n",
      "Let M = 23571113. N = f(M^{15}) - f(M^{15...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.1s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 424e18\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: A tournament is held with $2^{20}$ runners each of which has a different running speed. In each race...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 2221 chars\n",
      "[ALG] Classification response: analysisWe need to analyze the problem: tournament with 2^20 runners each with distinct speeds. In each round i (i from 1 to 20), we pair runners with equal scores at start of round. Winner gets 2^{20...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to analyze the problem: tournament with 2^20 runners each with distinct speeds. In each round i (i from 1 to 20), we pair runners with equal scores at start of round. Winner gets 2^{20...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 9020 chars\n",
      "[ALG] Lemma graph response: analysisWe need to produce a lemma graph (list of lemmas with dependencies) for the given problem. The problem: tournament with 2^20 runners each with distinct speeds. 20 rounds, each round pair runners with same current score. Winner gets 2^{20-i} points in round i (i from 1 to 20). At the end, we ...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to produce a lemma graph (list of lemmas with dependencies) for the given problem. The problem: tournament with 2^20 runners each with distinct speeds. 20 rounds, each round pair runne...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 8140 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve combinatorial problem: tournament with 2^20 runners, each distinct speed. In each round i (i=1..20), we pair runners with same score at start of round. Winner gets 2^{20-i} po...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.1s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: a295e9\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: A $500 \\times 500$ square is divided into $k$ rectangles, each having integer side lengths. Given th...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 2121 chars\n",
      "[ALG] Classification response: analysisWe need to classify the problem: It's about dividing a 500x500 square into rectangles with integer side lengths, each rectangle having distinct perimeter. Find maximum number of rectangles k, ...\n",
      "[WARNING] JSON parse error: Expecting value: line 1 column 1 (char 0)\n",
      "[DEBUG] Text snippet: analysisWe need to classify the problem: It's about dividing a 500x500 square into rectangles with integer side lengths, each rectangle having distinct perimeter. Find maximum number of rectangles k, ...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 6807 chars\n",
      "[ALG] Lemma graph response: analysisWe need to decompose the problem into lemmas and produce a JSON object with lemmas, final_lemma, and graph_strategy. The problem: \"A 500x500 square is divided into k rectangles, each having integer side lengths. Given that no two of these rectangles have the same perimeter, the largest possi...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to decompose the problem into lemmas and produce a JSON object with lemmas, final_lemma, and graph_strategy. The problem: \"A 500x500 square is divided into k rectangles, each having in...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 7637 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve the problem: A 500x500 square is divided into k rectangles, each having integer side lengths. No two rectangles have the same perimeter. Find the largest possible k (call it K...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.1s\n",
      "\n",
      "SUBMITTING: 0\n",
      "\n",
      "============================================================\n",
      "PROBLEM ID: 86e8e5\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROBLEM: Let $n \\geq 6$ be a positive integer. We call a positive integer $n$-Norwegian if it has three disti...\n",
      "============================================================\n",
      "\n",
      "=== PHASE 1: PROBLEM CLASSIFICATION ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=500)...\n",
      "[LLM] Generated 1743 chars\n",
      "[ALG] Classification response: analysisWe need to analyze the problem: It defines n-Norwegian numbers: a positive integer that has three distinct positive divisors whose sum equals n. So given n (>=6), we consider numbers that have...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to analyze the problem: It defines n-Norwegian numbers: a positive integer that has three distinct positive divisors whose sum equals n. So given n (>=6), we consider numbers that have...\n",
      "[ALG] Topic: algebra\n",
      "[ALG] Complexity: medium\n",
      "[ALG] Estimated lemmas: 4\n",
      "[ALG] Confidence: 0.50\n",
      "[ALG] Budget: 180s\n",
      "[ALG] Time budget: 180s\n",
      "\n",
      "=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===\n",
      "[LLM] Generating (temp=0.5, max_tokens=2000)...\n",
      "[LLM] Generated 6048 chars\n",
      "[ALG] Lemma graph response: analysisWe need to decompose the given problem into lemmas. The problem:\n",
      "\n",
      "Let n >= 6 be a positive integer. We call a positive integer n-Norwegian if it has three distinct positive divisors whose sum is equal to n. Let f(n) denote the smallest n-Norwegian positive integer. Let M = 3^{2025!} and for ...\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to decompose the given problem into lemmas. The problem:\n",
      "\n",
      "Let n >= 6 be a positive integer. We call a positive integer n-Norwegian if it has three distinct positive divisors whose sum ...\n",
      "[ALG] Graph created: 0 lemmas + final\n",
      "[ALG] Dependencies: []\n",
      "\n",
      "=== DIRECT SOLUTION (FALLBACK) ===\n",
      "[LLM] Generating (temp=0.3, max_tokens=2000)...\n",
      "[LLM] Generated 6476 chars\n",
      "[WARNING] JSON parse error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "[DEBUG] Text snippet: analysisWe need to solve a problem: Let n >= 6 be a positive integer. We call a positive integer n-Norwegian if it has three distinct positive divisors whose sum is equal to n. Let f(n) denote the sma...\n",
      "[ALG] Answer: 0, Confidence: 0.00, Time: 24.2s\n",
      "\n",
      "SUBMITTING: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == '__main__' or True:\n",
    "    if os.path.exists('/kaggle'):\n",
    "        # Read reference.csv with only first 2 columns (id, problem)\n",
    "        import pandas as pd\n",
    "        ref_path = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv'\n",
    "        ref_df = pd.read_csv(ref_path, usecols=[0, 1])\n",
    "        ref_df.columns = ['id', 'question']\n",
    "        test_path = '/kaggle/working/test.csv'\n",
    "        ref_df.to_csv(test_path, index=False)\n",
    "        print(f'Using reference.csv: {len(ref_df)} problems')\n",
    "        \n",
    "        server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n",
    "        if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "            server.serve()\n",
    "        else:\n",
    "            server.run_local_gateway((test_path,))\n",
    "    else:\n",
    "        print('Not on Kaggle')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "sourceId": 118448,
     "sourceType": "competition"
    },
    {
     "sourceId": 289055161,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 422384,
     "modelInstanceId": 404485,
     "sourceId": 510391,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 753.508993,
   "end_time": "2026-02-03T02:51:21.044069",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-03T02:38:47.535076",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
