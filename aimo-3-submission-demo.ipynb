{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AIMO Progress Prize 3 - H100 Inference Strategy\n",
                "\n",
                "This notebook implements a **Tool-Integrated Reasoning (TIR)** strategy.\n",
                "\n",
                "### Strategy Overview\n",
                "1.  **Model**: DeepSeek-R1-Distill-Qwen-32B (Reasoning Model)\n",
                "2.  **Inference**: vLLM for high-throughput generation.\n",
                "3.  **Methodology**: \n",
                "    *   **Generate**: Create $N=16$ candidate solutions (python code blocks).\n",
                "    *   **Execute**: Run the Python code to verify results.\n",
                "    *   **Vote**: Select the most common valid integer answer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "import re\n",
                "import math\n",
                "from typing import List, Optional, Any\n",
                "from collections import Counter\n",
                "\n",
                "import pandas as pd\n",
                "import polars as pl\n",
                "import kaggle_evaluation.aimo_3_inference_server\n",
                "\n",
                "# Attempt to import vLLM\n",
                "try:\n",
                "    from vllm import LLM, SamplingParams\n",
                "    VLLM_AVAILABLE = True\n",
                "except ImportError:\n",
                "    print(\"vLLM not installed. Running in dummy mode for testing.\")\n",
                "    VLLM_AVAILABLE = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CONFIGURATION ---\n",
                "# Path to your attached model dataset on Kaggle\n",
                "kKAGGLE_MODEL_PATH = \"/kaggle/input/deepseek-r1-distill-qwen-32b/transformers/default/1\"\n",
                "LOCAL_MODEL_PATH = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\" # For local testing if needed\n",
                "\n",
                "if os.path.exists(kKAGGLE_MODEL_PATH):\n",
                "    MODEL_PATH = kKAGGLE_MODEL_PATH\n",
                "else:\n",
                "    MODEL_PATH = LOCAL_MODEL_PATH\n",
                "\n",
                "# Inference Parameters\n",
                "N_SAMPLES = 16  # How many solutions to generate per problem (Scaling N increases score)\n",
                "MAX_TOKENS = 2048\n",
                "TEMPERATURE = 0.6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- PYTHON WRAPPER (SANDBOX) ---\n",
                "import multiprocessing\n",
                "import io\n",
                "import contextlib\n",
                "\n",
                "def _exec_wrapper(code, queue):\n",
                "    \"\"\"Worker function to execute code safely.\"\"\"\n",
                "    buffer = io.StringIO()\n",
                "    try:\n",
                "        # Redirect stdout to capture print() outputs\n",
                "        with contextlib.redirect_stdout(buffer):\n",
                "            # Create a safe globals dictionary\n",
                "            safe_globals = {\"math\": math, \"__builtins__\": __builtins__}\n",
                "            exec(code, safe_globals)\n",
                "        queue.put((True, buffer.getvalue()))\n",
                "    except Exception as e:\n",
                "        queue.put((False, str(e)))\n",
                "\n",
                "def execute_python_code(code: str, timeout: int = 5) -> Optional[str]:\n",
                "    \"\"\"\n",
                "    Executes Python code in a separate process with a timeout.\n",
                "    Returns the stdout output if successful, or None on failure/timeout.\n",
                "    \"\"\"\n",
                "    q = multiprocessing.Queue()\n",
                "    p = multiprocessing.Process(target=_exec_wrapper, args=(code, q))\n",
                "    p.start()\n",
                "    p.join(timeout)\n",
                "    \n",
                "    if p.is_alive():\n",
                "        p.terminate()\n",
                "        p.join()\n",
                "        return None # Timeout\n",
                "    \n",
                "    if not q.empty():\n",
                "        success, result = q.get()\n",
                "        if success:\n",
                "            return result.strip()\n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- RESULT PARSING ---\n",
                "def extract_python_code(text: str) -> Optional[str]:\n",
                "    \"\"\"Extracts the first code block from markdown text.\"\"\"\n",
                "    match = re.search(r'```python\\s*(.*?)\\s*```', text, re.DOTALL)\n",
                "    if match:\n",
                "        return match.group(1)\n",
                "    # Fallback: looks for print statements if no code block\n",
                "    if \"print(\" in text:\n",
                "        return text\n",
                "    return None\n",
                "\n",
                "def extract_final_answer(text: str) -> Optional[int]:\n",
                "    \"\"\"Attempts to parse the final integer answer.\"\"\"\n",
                "    # 1. Look for \\boxed{123}\n",
                "    boxed_match = re.search(r'\\\\boxed\\{(\\d+)\\}', text)\n",
                "    if boxed_match:\n",
                "        return int(boxed_match.group(1))\n",
                "    \n",
                "    # 2. Look for explicit number at end\n",
                "    numbers = re.findall(r'\\b\\d+\\b', text)\n",
                "    if numbers:\n",
                "        return int(numbers[-1])\n",
                "        \n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- INFERENCE ENGINE ---\n",
                "class TIRSolver:\n",
                "    def __init__(self, model_path: str):\n",
                "        if VLLM_AVAILABLE:\n",
                "            print(f\"Loading vLLM model from {model_path}...\")\n",
                "            # Initialize vLLM\n",
                "            self.llm = LLM(\n",
                "                model=model_path,\n",
                "                tensor_parallel_size=1, # 1 GPU\n",
                "                dtype=\"auto\",\n",
                "                trust_remote_code=True,\n",
                "                enforce_eager=True # Often needed for Kaggle\n",
                "            )\n",
                "            self.sampling_params = SamplingParams(\n",
                "                n=N_SAMPLES,\n",
                "                temperature=TEMPERATURE,\n",
                "                top_p=0.95,\n",
                "                max_tokens=MAX_TOKENS\n",
                "            )\n",
                "        else:\n",
                "            self.llm = None\n",
                "\n",
                "    def generate_prompt(self, problem: str) -> str:\n",
                "        \"\"\"Creates a Tool-Integrated Reasoning prompt.\"\"\"\n",
                "        return f\"\"\"User: Solve the following math problem. \n",
                "To help you, you can write and execute Python code. \n",
                "Surround your Python code with ```python and ```.\n",
                "Even if you write code, you MUST end your response with the final answer inside \\\\boxed{{...}}.\n",
                "The answer must be a non-negative integer (0-99999).\n",
                "\n",
                "Problem: {problem}\n",
                "\n",
                "Assistant:\"\"\"\n",
                "\n",
                "    def solve(self, problem_text: str) -> int:\n",
                "        if not self.llm:\n",
                "            return 0 # Dummy mode\n",
                "            \n",
                "        prompts = [self.generate_prompt(problem_text)]\n",
                "        \n",
                "        # 1. Generate N Candidate Solutions\n",
                "        outputs = self.llm.generate(prompts, self.sampling_params, use_tqdm=False)\n",
                "        candidates = []\n",
                "        \n",
                "        for output in outputs[0].outputs:\n",
                "            text = output.text\n",
                "            \n",
                "            # 2. Check for Code and Execute\n",
                "            code = extract_python_code(text)\n",
                "            if code:\n",
                "                # Run the code to verify/calculate\n",
                "                exec_result = execute_python_code(code)\n",
                "                if exec_result and exec_result.isdigit():\n",
                "                    # If code printed a number, use that as a strong candidate\n",
                "                    candidates.append(int(exec_result))\n",
                "                    continue\n",
                "            \n",
                "            # 3. Fallback: Parse text for \\boxed{}\n",
                "            ans = extract_final_answer(text)\n",
                "            if ans is not None:\n",
                "                candidates.append(ans)\n",
                "        \n",
                "        # 4. Majority Vote\n",
                "        valid_candidates = [c for c in candidates if 0 <= c <= 99999]\n",
                "        if not valid_candidates:\n",
                "            return 0 # Default fallback\n",
                "            \n",
                "        # Weighted voting could go here. For now, simple majority.\n",
                "        counts = Counter(valid_candidates)\n",
                "        best_answer, _ = counts.most_common(1)[0]\n",
                "        return best_answer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Model Once\n",
                "# Note: In the competition, this runs during container startup\n",
                "solver = TIRSolver(MODEL_PATH)\n",
                "\n",
                "def predict(id_: pl.Series, problem: pl.Series) -> pl.DataFrame | pd.DataFrame:\n",
                "    \"\"\"Kaggle Competition Entry Point\"\"\"\n",
                "    id_val = id_.item(0)\n",
                "    problem_text = problem.item(0)\n",
                "    \n",
                "    # Solve\n",
                "    prediction = solver.solve(problem_text)\n",
                "    \n",
                "    return pl.DataFrame({'id': id_val, 'answer': prediction})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start the Inference Server\n",
                "inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(\n",
                "    predict\n",
                ")\n",
                "\n",
                "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
                "    inference_server.serve()\n",
                "else:\n",
                "    # Local test gateway\n",
                "    inference_server.run_local_gateway(\n",
                "        ('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv',)\n",
                "    )"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": false,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}