{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "sourceId": 118448,
     "databundleVersionId": 14559231,
     "sourceType": "competition"
    },
    {
     "sourceId": 289055161,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 510391,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 404485,
     "modelId": 422384
    }
   ],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "intro",
   "cell_type": "markdown",
   "source": "# ALG Sequential Solver for AIMO3\n\nAdaptive Lemma Graph solver with:\n1. **Problem Classification** - Model determines topic and complexity\n2. **Topic-Specific DAG** - Build lemma graph based on problem type\n3. **Dynamic Time Allocation** - Spend more time on hard problems\n4. **Sequential Traversal** - No parallel threads, one rigorous proof path\n\nStrategy:\n- Simple problems (2-3 lemmas): ~60 seconds\n- Medium problems (4-5 lemmas): ~180 seconds\n- Hard problems (6-8 lemmas): ~480 seconds\n",
   "metadata": {}
  },
  {
   "id": "uninstall",
   "cell_type": "code",
   "source": "%pip uninstall --yes 'keras' 'matplotlib' 'scikit-learn' 'tensorflow'\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:42.479109Z",
     "iopub.execute_input": "2026-02-03T01:13:42.479740Z",
     "iopub.status.idle": "2026-02-03T01:13:43.984429Z",
     "shell.execute_reply.started": "2026-02-03T01:13:42.479722Z",
     "shell.execute_reply": "2026-02-03T01:13:43.983899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping matplotlib as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping scikit-learn as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 119
  },
  {
   "id": "basic_imports",
   "cell_type": "code",
   "source": "import warnings\nwarnings.simplefilter('ignore')\n\nimport os\nimport sys\nimport subprocess\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:43.985457Z",
     "iopub.execute_input": "2026-02-03T01:13:43.985613Z",
     "iopub.status.idle": "2026-02-03T01:13:43.988652Z",
     "shell.execute_reply.started": "2026-02-03T01:13:43.985596Z",
     "shell.execute_reply": "2026-02-03T01:13:43.988226Z"
    }
   },
   "outputs": [],
   "execution_count": 120
  },
  {
   "id": "setup_env",
   "cell_type": "code",
   "source": "def set_env(input_archive, temp_dir):\n    if not os.path.exists(temp_dir):\n        os.makedirs(temp_dir, exist_ok=True)\n        subprocess.run(['tar', '-xzf', input_archive, '-C', temp_dir], check=True)\n    \n    subprocess.run([\n        sys.executable,\n        '-m',\n        'pip',\n        'install',\n        '--no-index',\n        '--find-links',\n        f'{temp_dir}/wheels',\n        'unsloth',\n        'trl',\n        'vllm',\n        'openai_harmony'\n    ], check=True)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:43.989182Z",
     "iopub.execute_input": "2026-02-03T01:13:43.989302Z",
     "iopub.status.idle": "2026-02-03T01:13:43.998487Z",
     "shell.execute_reply.started": "2026-02-03T01:13:43.989291Z",
     "shell.execute_reply": "2026-02-03T01:13:43.998102Z"
    }
   },
   "outputs": [],
   "execution_count": 121
  },
  {
   "id": "install_deps",
   "cell_type": "code",
   "source": "set_env(\n    input_archive='/kaggle/input/aimo-3-utils/wheels.tar.gz',\n    temp_dir='/kaggle/tmp/setup'\n)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:43.999412Z",
     "iopub.execute_input": "2026-02-03T01:13:43.999551Z",
     "iopub.status.idle": "2026-02-03T01:13:47.183189Z",
     "shell.execute_reply.started": "2026-02-03T01:13:43.999539Z",
     "shell.execute_reply": "2026-02-03T01:13:47.182731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Looking in links: /kaggle/tmp/setup/wheels\nRequirement already satisfied: unsloth in /usr/local/lib/python3.12/dist-packages (2025.12.9)\nRequirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.24.0)\nRequirement already satisfied: vllm in /usr/local/lib/python3.12/dist-packages (0.11.2)\nRequirement already satisfied: openai_harmony in /usr/local/lib/python3.12/dist-packages (0.0.8)\nRequirement already satisfied: unsloth_zoo>=2025.12.7 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2025.12.7)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (26.0rc2)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.9.0+cu128)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.24.0+cu128)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.0.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.0.33.post1)\nRequirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.49.0)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.5.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\nRequirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.3.0)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.11.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.2)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2025.11.3)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (5.5.2)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.5)\nRequirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.0.8)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\nRequirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\nRequirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.123.10)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.3)\nRequirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.15.0)\nRequirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.5)\nRequirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\nRequirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (7.1.0)\nRequirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\nRequirement already satisfied: lm-format-enforcer==0.11.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.11.3)\nRequirement already satisfied: llguidance<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.3.0)\nRequirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.11)\nRequirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (5.6.3)\nRequirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.2.2)\nRequirement already satisfied: xgrammar==0.1.25 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.1.25)\nRequirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\nRequirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.3)\nRequirement already satisfied: partial-json-parser in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1.1.post7)\nRequirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\nRequirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from vllm) (0.20.0)\nRequirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.17.1)\nRequirement already satisfied: mistral_common>=1.8.5 in /usr/local/lib/python3.12/dist-packages (from mistral_common[image]>=1.8.5->vllm) (1.8.8)\nRequirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\nRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\nRequirement already satisfied: setuptools<81.0.0,>=77.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (80.9.0)\nRequirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\nRequirement already satisfied: compressed-tensors==0.12.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.2)\nRequirement already satisfied: depyf==0.20.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.20.0)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.1)\nRequirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm) (1.1.1)\nRequirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.15.3)\nRequirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm) (1.13.0)\nRequirement already satisfied: pybase64 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.4.3)\nRequirement already satisfied: cbor2 in /usr/local/lib/python3.12/dist-packages (from vllm) (5.7.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from vllm) (1.3.7)\nRequirement already satisfied: anthropic==0.71.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.71.0)\nRequirement already satisfied: model-hosting-container-standards<1.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.1.12)\nRequirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.61.2)\nRequirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (2.53.0)\nRequirement already satisfied: torchaudio==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.9.0+cu128)\nRequirement already satisfied: flashinfer-python==0.5.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.5.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (4.12.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.9.0)\nRequirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.17.0)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.10.0)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.3.1)\nRequirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->vllm) (0.7.3)\nRequirement already satisfied: astor in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.8.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.4.0)\nRequirement already satisfied: apache-tvm-ffi<0.2,>=0.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (0.1.7)\nRequirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (8.3.1)\nRequirement already satisfied: nvidia-cudnn-frontend>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (1.17.0)\nRequirement already satisfied: nvidia-cutlass-dsl>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (4.3.4)\nRequirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (12.575.51)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (0.9.0)\nRequirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm) (0.3.3)\nRequirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->vllm) (0.44.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\nRequirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.93)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.90)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.90)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.8.93)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.90)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.8.93)\nRequirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.1.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.6.2)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\nRequirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.50.0)\nRequirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.0.4)\nRequirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.20)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\nRequirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.3.0)\nRequirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.1rc0)\nRequirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (4.25.1)\nRequirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2.10.6)\nRequirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0->vllm) (1.0.1)\nRequirement already satisfied: supervisor>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0->vllm) (4.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.4.2)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\nRequirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2026.1.4)\nRequirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.15.0+cu128)\nRequirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (25.1.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.8.0)\nRequirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\nRequirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.17.1)\nRequirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.8.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.27.1)\nRequirement already satisfied: cuda-python>=12.8 in /usr/local/lib/python3.12/dist-packages (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm) (13.1.1)\nRequirement already satisfied: pycountry>=23 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (24.6.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.1)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\nRequirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.22.1)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: cuda-bindings~=13.1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm) (13.1.1)\nRequirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm) (1.3.3)\nRequirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.6)\nRequirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.42.1)\nRequirement already satisfied: fastar>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.8.0)\nRequirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.2.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 122
  },
  {
   "id": "env_vars",
   "cell_type": "code",
   "source": "os.environ['TRANSFORMERS_NO_TF'] = '1'\nos.environ['TRANSFORMERS_NO_FLAX'] = '1'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nos.environ['TRITON_PTXAS_PATH'] = '/usr/local/cuda/bin/ptxas'\nos.environ['TIKTOKEN_ENCODINGS_BASE'] = '/kaggle/tmp/setup/tiktoken_encodings'\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.183802Z",
     "iopub.execute_input": "2026-02-03T01:13:47.183930Z",
     "iopub.status.idle": "2026-02-03T01:13:47.186720Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.183917Z",
     "shell.execute_reply": "2026-02-03T01:13:47.186344Z"
    }
   },
   "outputs": [],
   "execution_count": 123
  },
  {
   "id": "imports",
   "cell_type": "code",
   "source": "# ============================================================\n# IMPORTS\n# ============================================================\n\nimport gc\nimport re\nimport json\nimport math\nimport time\nimport queue\nimport threading\nimport contextlib\nfrom typing import Optional, List, Dict, Tuple, Any\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict\nfrom enum import Enum\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nimport pandas as pd\nimport polars as pl\n\nfrom openai import OpenAI\n\nfrom openai_harmony import (\n    HarmonyEncodingName,\n    load_harmony_encoding,\n    SystemContent,\n    ReasoningEffort,\n    ToolNamespaceConfig,\n    Author,\n    Message,\n    Role,\n    TextContent,\n    Conversation\n)\n\nfrom transformers import set_seed\nimport kaggle_evaluation.aimo_3_inference_server\n\nprint('All imports done')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.187288Z",
     "iopub.execute_input": "2026-02-03T01:13:47.187455Z",
     "iopub.status.idle": "2026-02-03T01:13:47.197828Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.187442Z",
     "shell.execute_reply": "2026-02-03T01:13:47.197442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "All imports done\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 124
  },
  {
   "id": "config",
   "cell_type": "code",
   "source": "# ============================================================\n# CONFIGURATION\n# ============================================================\n\nclass CFG:\n    # Model settings\n    model_path = '/kaggle/input/gpt-oss-120b/transformers/default/1'\n    served_model_name = 'gpt-oss'\n    \n    # Inference settings\n    context_tokens = 65536\n    temperature = 0.7\n    top_p = 0.95\n    max_tokens_per_turn = 4096\n    \n    # Time budgets (seconds) based on complexity\n    time_budget = {\n        'simple': 60,\n        'medium': 180,\n        'hard': 480,\n        'default': 180\n    }\n    \n    # Lemma settings\n    max_lemmas = 8\n    max_retries_per_lemma = 3\n    \n    # Python sandbox\n    sandbox_timeout = 30\n    \n    # Server settings\n    server_port = 8000\n    server_timeout = 180\n    \n    # vLLM settings\n    kv_cache_dtype = 'fp8_e4m3'\n    dtype = 'auto'\n    gpu_memory_utilization = 0.96\n    batch_size = 256\n    \n    print('Configuration loaded')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.198313Z",
     "iopub.execute_input": "2026-02-03T01:13:47.198455Z",
     "iopub.status.idle": "2026-02-03T01:13:47.207147Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.198443Z",
     "shell.execute_reply": "2026-02-03T01:13:47.206685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Configuration loaded\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 125
  },
  {
   "id": "seed",
   "cell_type": "code",
   "source": "set_seed(42)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.207716Z",
     "iopub.execute_input": "2026-02-03T01:13:47.207843Z",
     "iopub.status.idle": "2026-02-03T01:13:47.217304Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.207832Z",
     "shell.execute_reply": "2026-02-03T01:13:47.216952Z"
    }
   },
   "outputs": [],
   "execution_count": 126
  },
  {
   "id": "prompts",
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# SYSTEM PROMPTS\n",
    "# ============================================================\n",
    "\n",
    "CLASSIFICATION_PROMPT = \"\"\"Analyze this mathematical problem and classify it.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Respond with ONLY a JSON object in this exact format:\n",
    "{\n",
    "  \"topic\": \"algebra\",\n",
    "  \"complexity\": \"hard\",\n",
    "  \"key_techniques\": [\"modular arithmetic\", \"Diophantine equations\"],\n",
    "  \"estimated_lemmas\": 6,\n",
    "  \"reasoning\": \"This problem requires advanced number theory\"\n",
    "}\n",
    "\n",
    "topic: algebra | number_theory | combinatorics | geometry | analysis\n",
    "complexity: simple | medium | hard\n",
    "\"\"\"\n",
    "\n",
    "LEMMA_GRAPH_PROMPT = \"\"\"Decompose this problem into lemmas.\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Respond with ONLY a JSON object in this exact format:\n",
    "{\n",
    "  \"lemmas\": [\n",
    "    {\n",
    "      \"id\": \"L1\",\n",
    "      \"type\": \"structural\",\n",
    "      \"statement\": \"The set forms a group under operation\",\n",
    "      \"dependencies\": [],\n",
    "      \"verification\": \"Check group axioms with Python\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"L2\",\n",
    "      \"type\": \"reduction\",\n",
    "      \"statement\": \"Counting reduces to divisor counting\",\n",
    "      \"dependencies\": [\"L1\"],\n",
    "      \"verification\": \"Establish bijection with Python\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"L3\",\n",
    "      \"type\": \"computational\",\n",
    "      \"statement\": \"Compute the divisor count\",\n",
    "      \"dependencies\": [\"L2\"],\n",
    "      \"verification\": \"Python calculation\"\n",
    "    }\n",
    "  ],\n",
    "  \"final\": {\n",
    "    \"computation\": \"Multiply results and take modulo\",\n",
    "    \"dependencies\": [\"L1\", \"L2\", \"L3\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "types: structural | reduction | computational | verification\n",
    "dependencies: use lemma ids like [\"L1\", \"L2\"] or [] for none\n",
    "Create exactly {estimated_lemmas} lemmas.\n",
    "\"\"\"\n",
    "\n",
    "SYNTHESIS_PROMPT = \"\"\"Given these verified lemmas, compute the final answer.\n",
    "\n",
    "Verified Lemmas: {lemmas}\n",
    "Problem: {problem}\n",
    "\n",
    "Respond with ONLY a JSON object:\n",
    "{\n",
    "  \"reasoning\": \"Step-by-step combination of lemmas\",\n",
    "  \"answer\": 42,\n",
    "  \"verification\": \"Quick check that answer satisfies constraints\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompts defined\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.217857Z",
     "iopub.execute_input": "2026-02-03T01:13:47.217988Z",
     "iopub.status.idle": "2026-02-03T01:13:47.225155Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.217975Z",
     "shell.execute_reply": "2026-02-03T01:13:47.224788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Prompts defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 127
  },
  {
   "id": "data_structures",
   "cell_type": "code",
   "source": "# ============================================================\n# DATA STRUCTURES\n# ============================================================\n\nclass Complexity(Enum):\n    SIMPLE = 'simple'\n    MEDIUM = 'medium'\n    HARD = 'hard'\n\nclass LemmaType(Enum):\n    STRUCTURAL = 'structural'\n    REDUCTION = 'reduction'\n    COMPUTATIONAL = 'computational'\n    VERIFICATION = 'verification'\n    SYNTHESIS = 'synthesis'\n\n@dataclass\nclass ProblemClassification:\n    topic: str\n    complexity: Complexity\n    key_techniques: List[str] = field(default_factory=list)\n    estimated_lemmas: int = 4\n    reasoning: str = ''\n    \n    def get_time_budget(self) -> float:\n        return CFG.time_budget.get(self.complexity.value, CFG.time_budget['default'])\n\n@dataclass\nclass Lemma:\n    id: str\n    statement: str\n    lemma_type: LemmaType\n    dependencies: List[str] = field(default_factory=list)\n    verification_strategy: str = ''\n    proof: str = ''\n    verification_code: str = ''\n    execution_result: Optional[str] = None\n    verified: bool = False\n\n@dataclass\nclass LemmaGraph:\n    problem: str\n    classification: ProblemClassification\n    lemmas: Dict[str, Lemma] = field(default_factory=dict)\n    \n    def get_dependency_order(self) -> List[str]:\n        in_degree = {lid: 0 for lid in self.lemmas}\n        for lemma in self.lemmas.values():\n            for dep in lemma.dependencies:\n                if dep in in_degree:\n                    in_degree[lemma.id] += 1\n        queue = [lid for lid, deg in in_degree.items() if deg == 0]\n        result = []\n        while queue:\n            lid = queue.pop(0)\n            result.append(lid)\n            for lemma in self.lemmas.values():\n                if lid in lemma.dependencies:\n                    in_degree[lemma.id] -= 1\n                    if in_degree[lemma.id] == 0:\n                        queue.append(lemma.id)\n        return result\n\n@dataclass\nclass SolutionResult:\n    problem: str\n    classification: ProblemClassification\n    answer: Optional[int] = None\n    success: bool = False\n    time_taken: float = 0.0\n\nprint('Data structures defined')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.226280Z",
     "iopub.execute_input": "2026-02-03T01:13:47.226438Z",
     "iopub.status.idle": "2026-02-03T01:13:47.239227Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.226426Z",
     "shell.execute_reply": "2026-02-03T01:13:47.238850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Data structures defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 128
  },
  {
   "id": "sandbox",
   "cell_type": "code",
   "source": "# ============================================================\n# JUPYTER SANDBOX\n# ============================================================\n\nfrom jupyter_client import KernelManager\n\nclass ALGSandbox:\n    _port_lock = threading.Lock()\n    _next_port = 50000\n    \n    @classmethod\n    def _get_next_ports(cls, count=5):\n        with cls._port_lock:\n            ports = list(range(cls._next_port, cls._next_port + count))\n            cls._next_port += count\n            return ports\n    \n    def __init__(self, timeout=30.0):\n        self.timeout = timeout\n        ports = self._get_next_ports(5)\n        env = os.environ.copy()\n        env['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n        env['PYTHONWARNINGS'] = 'ignore'\n        \n        self._km = KernelManager()\n        self._km.shell_port = ports[0]\n        self._km.iopub_port = ports[1]\n        self._km.stdin_port = ports[2]\n        self._km.hb_port = ports[3]\n        self._km.control_port = ports[4]\n        \n        self._km.start_kernel(env=env)\n        self._client = self._km.blocking_client()\n        self._client.start_channels()\n        self._client.wait_for_ready(timeout=30)\n        \n        init_code = '''import math\nimport sympy as sp\nimport itertools\nimport numpy as np'''\n        self.execute(init_code)\n    \n    def execute(self, code, timeout=None):\n        timeout = timeout or self.timeout\n        msg_id = self._client.execute(code, store_history=False)\n        stdout, stderr = [], []\n        start = time.time()\n        while True:\n            if time.time() - start > timeout:\n                self._km.interrupt_kernel()\n                return {'success': False, 'output': '', 'error': 'Timeout'}\n            try:\n                msg = self._client.get_iopub_msg(timeout=1.0)\n            except Exception:\n                continue\n            if msg.get('parent_header', {}).get('msg_id') != msg_id:\n                continue\n            msg_type = msg.get('msg_type')\n            content = msg.get('content', {})\n            if msg_type == 'stream':\n                text = content.get('text', '')\n                if content.get('name') == 'stdout':\n                    stdout.append(text)\n                else:\n                    stderr.append(text)\n            elif msg_type == 'error':\n                stderr.append('\\n'.join(content.get('traceback', [])))\n            elif msg_type == 'status' and content.get('execution_state') == 'idle':\n                break\n        stdout, stderr = ''.join(stdout), ''.join(stderr)\n        if stderr:\n            return {'success': False, 'output': stdout, 'error': stderr}\n        return {'success': True, 'output': stdout.strip(), 'error': None}\n    \n    def close(self):\n        if self._client:\n            self._client.stop_channels()\n        if self._km:\n            self._km.shutdown_kernel(now=True)\n\nprint('Sandbox defined')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.239746Z",
     "iopub.execute_input": "2026-02-03T01:13:47.239868Z",
     "iopub.status.idle": "2026-02-03T01:13:47.250367Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.239857Z",
     "shell.execute_reply": "2026-02-03T01:13:47.249977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Sandbox defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 129
  },
  {
   "id": "llm_interface",
   "cell_type": "code",
   "source": "# ============================================================\n# LLM INTERFACE\n# ============================================================\n\nclass LLMInterface:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.base_url = f'http://0.0.0.0:{cfg.server_port}/v1'\n        self.api_key = 'sk-local'\n        self.client = None\n        self.encoding = None\n        self.stop_token_ids = None\n    \n    def initialize(self):\n        print('[LLM] Connecting to vLLM server...', flush=True)\n        self.client = OpenAI(base_url=self.base_url, api_key=self.api_key, timeout=300)\n        self.encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n        self.stop_token_ids = self.encoding.stop_tokens_for_assistant_actions()\n        print('[LLM] Connected successfully', flush=True)\n    \n    def generate(self, system_prompt, user_prompt, temperature=None, max_tokens=None):\n        temp = temperature or self.cfg.temperature\n        max_tok = max_tokens or self.cfg.max_tokens_per_turn\n        print(f'[LLM] Generating (temp={temp}, max_tokens={max_tok})...', flush=True)\n        if not self.client:\n            raise RuntimeError('LLM client not initialized!')\n        if not self.encoding:\n            raise RuntimeError('Encoding not initialized!')\n        \n        system_content = (SystemContent.new()\n            .with_model_identity(system_prompt)\n            .with_reasoning_effort(reasoning_effort=ReasoningEffort.HIGH))\n        system_msg = Message.from_role_and_content(Role.SYSTEM, system_content)\n        user_msg = Message.from_role_and_content(Role.USER, TextContent(text=user_prompt))\n        conversation = Conversation.from_messages([system_msg, user_msg])\n        prompt_ids = self.encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)\n        \n        response = self.client.completions.create(\n            model=self.cfg.served_model_name,\n            temperature=temp,\n            max_tokens=max_tok,\n            prompt=prompt_ids,\n            stop=None)\n        \n        result = response.choices[0].text\n        print(f'[LLM] Generated {len(result)} chars', flush=True)\n        return result\n\nprint('LLM interface defined')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.250848Z",
     "iopub.execute_input": "2026-02-03T01:13:47.250971Z",
     "iopub.status.idle": "2026-02-03T01:13:47.260342Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.250959Z",
     "shell.execute_reply": "2026-02-03T01:13:47.259948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "LLM interface defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 130
  },
  {
   "id": "parsing_utils",
   "cell_type": "code",
   "source": "# ============================================================\n# PARSING UTILITIES\n# ============================================================\n\nclass ParsingUtils:\n    @staticmethod\n    def parse_classification(text):\n        topic, complexity = 'algebra', Complexity.MEDIUM\n        techniques, reasoning = [], ''\n        estimated = 4\n        for line in text.split('\\n'):\n            line = line.strip()\n            if line.startswith('TOPIC:'):\n                topic = line.split(':', 1)[1].strip().lower()\n            elif line.startswith('COMPLEXITY:'):\n                comp = line.split(':', 1)[1].strip().lower()\n                if comp in ['simple', 'easy']: complexity = Complexity.SIMPLE\n                elif comp == 'hard': complexity = Complexity.HARD\n            elif line.startswith('KEY_TECHNIQUES:'):\n                tech_str = line.split(':', 1)[1].strip()\n                techniques = [t.strip() for t in tech_str.split(',') if t.strip()]\n            elif line.startswith('ESTIMATED_LEMMAS:'):\n                try: estimated = int(line.split(':', 1)[1].strip())\n                except: pass\n            elif line.startswith('REASONING:'):\n                reasoning = line.split(':', 1)[1].strip()\n        estimated = max(2, min(estimated, CFG.max_lemmas))\n        return ProblemClassification(topic, complexity, techniques, estimated, reasoning)\n    \n    @staticmethod\n    def parse_lemma_graph(text, problem, classification):\n        graph = LemmaGraph(problem, classification)\n        # Simple parsing - look for Lemma lines\n        for line in text.split('\\n'):\n            line = line.strip()\n            if '**Lemma' in line and '**' in line:\n                match = re.search(r'Lemma\\s*(\\d+)', line, re.IGNORECASE)\n                if match:\n                    lemma_id = f'L{match.group(1)}'\n                    ltype = LemmaType.STRUCTURAL\n                    if 'reduction' in line.lower(): ltype = LemmaType.REDUCTION\n                    elif 'computational' in line.lower(): ltype = LemmaType.COMPUTATIONAL\n                    lemma = Lemma(id=lemma_id, statement=line, lemma_type=ltype)\n                    graph.lemmas[lemma_id] = lemma\n            elif '**FINAL**' in line:\n                deps = [lid for lid in graph.lemmas.keys() if lid != 'FINAL']\n                graph.lemmas['FINAL'] = Lemma(id='FINAL', statement='Synthesize final answer',\n                                              lemma_type=LemmaType.SYNTHESIS, dependencies=deps)\n        if 'FINAL' not in graph.lemmas:\n            deps = [lid for lid in graph.lemmas.keys() if lid != 'FINAL']\n            graph.lemmas['FINAL'] = Lemma(id='FINAL', statement='Synthesize final answer',\n                                          lemma_type=LemmaType.SYNTHESIS, dependencies=deps)\n        return graph\n    \n    @staticmethod\n    def extract_answer(text):\n        matches = re.findall(r'boxed\\s*\\{\\s*([0-9,]+)\\s*\\}', text)\n        if matches:\n            try:\n                val = int(matches[-1].replace(',', ''))\n                if 0 <= val <= 99999: return val\n            except: pass\n        return None\n\nprint('Parsing utilities defined')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.260855Z",
     "iopub.execute_input": "2026-02-03T01:13:47.260987Z",
     "iopub.status.idle": "2026-02-03T01:13:47.270897Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.260975Z",
     "shell.execute_reply": "2026-02-03T01:13:47.270508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Parsing utilities defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 131
  },
  {
   "id": "alg_solver",
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# ALG SOLVER\n",
    "# ============================================================\n",
    "\n",
    "class ALGSolver:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.llm = LLMInterface(cfg)\n",
    "        self.sandbox = None\n",
    "        self.parser = ParsingUtils()\n",
    "\n",
    "    def initialize(self):\n",
    "        print('[ALG] Initializing...')\n",
    "        sys.stdout.flush()\n",
    "        self.sandbox = ALGSandbox(timeout=self.cfg.sandbox_timeout)\n",
    "        self.llm.initialize()\n",
    "        print('[ALG] Ready')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def classify_problem(self, problem):\n",
    "        print('\\n=== PHASE 1: PROBLEM CLASSIFICATION ===')\n",
    "        sys.stdout.flush()\n",
    "        prompt = CLASSIFICATION_PROMPT.format(problem=problem)\n",
    "        print('[ALG] Sending to LLM...')\n",
    "        sys.stdout.flush()\n",
    "        response = self.llm.generate('You output JSON only.', prompt, 0.3, 500)\n",
    "        print(f'[ALG] Raw response: {repr(response[:200])}')\n",
    "        sys.stdout.flush()\n",
    "        classification = self.parser.parse_classification(response)\n",
    "        print(f'[ALG] Topic: {classification.topic}')\n",
    "        print(f'[ALG] Complexity: {classification.complexity.value}')\n",
    "        print(f'[ALG] Budget: {classification.get_time_budget()}s')\n",
    "        sys.stdout.flush()\n",
    "        return classification\n",
    "\n",
    "    def build_lemma_graph(self, problem, classification):\n",
    "        print('\\n=== PHASE 2: LEMMA GRAPH ===')\n",
    "        sys.stdout.flush()\n",
    "        prompt = LEMMA_GRAPH_PROMPT.format(\n",
    "            estimated_lemmas=classification.estimated_lemmas, problem=problem)\n",
    "        response = self.llm.generate('You output JSON only.', prompt, 0.5, 2000)\n",
    "        graph = self.parser.parse_lemma_graph(response, problem, classification)\n",
    "        print(f'[ALG] Lemmas: {len(graph.lemmas)}')\n",
    "        print(f'[ALG] Order: {graph.get_dependency_order()}')\n",
    "        sys.stdout.flush()\n",
    "        return graph\n",
    "\n",
    "    def solve(self, problem):\n",
    "        start = time.time()\n",
    "        print('='*60)\n",
    "        print(f'PROBLEM: {problem[:80]}...')\n",
    "        print('='*60)\n",
    "        sys.stdout.flush()\n",
    "        try:\n",
    "            classification = self.classify_problem(problem)\n",
    "            graph = self.build_lemma_graph(problem, classification)\n",
    "            print('\\n=== PHASE 3: SYNTHESIS ===')\n",
    "            sys.stdout.flush()\n",
    "            # Prepare lemma summary\n",
    "            lemma_summary = []\n",
    "            for lid, l in graph.lemmas.items():\n",
    "                if lid != \"FINAL\":\n",
    "                    lemma_summary.append(f\"{lid}: {l.statement[:40]}\")\n",
    "            lemmas_str = \"; \".join(lemma_summary)\n",
    "            prompt = SYNTHESIS_PROMPT.format(lemmas=lemmas_str, problem=problem)\n",
    "            response = self.llm.generate('You output JSON only.', prompt, 0.7, 1000)\n",
    "            answer = self.parser.extract_answer(response)\n",
    "            elapsed = time.time() - start\n",
    "            print(f'[ALG] Answer: {answer}, Time: {elapsed:.1f}s')\n",
    "            sys.stdout.flush()\n",
    "            return SolutionResult(problem, classification, answer, answer is not None, elapsed)\n",
    "        except Exception as e:\n",
    "            print(f'[ALG] ERROR: {e}')\n",
    "            traceback.print_exc()\n",
    "            sys.stdout.flush()\n",
    "            return SolutionResult(problem, ProblemClassification(\"unknown\", Complexity.MEDIUM),\n",
    "                                  None, False, time.time() - start)\n",
    "\n",
    "print(\"ALG Solver defined\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.271429Z",
     "iopub.execute_input": "2026-02-03T01:13:47.271561Z",
     "iopub.status.idle": "2026-02-03T01:13:47.282467Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.271550Z",
     "shell.execute_reply": "2026-02-03T01:13:47.282058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ALG Solver defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 132
  },
  {
   "id": "server_manager",
   "cell_type": "code",
   "source": "# ============================================================\n# SERVER MANAGER\n# ============================================================\n\nclass ServerManager:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.server_process = None\n        self.log_file = None\n    \n    def preload_model(self):\n        print(f'Loading model from {self.cfg.model_path}...')\n        start = time.time()\n        files = []\n        for root, _, fs in os.walk(self.cfg.model_path):\n            for f in fs:\n                path = os.path.join(root, f)\n                if os.path.isfile(path): files.append(path)\n        def read_file(path):\n            with open(path, 'rb') as f:\n                while f.read(1024 * 1024 * 1024): pass\n        with ThreadPoolExecutor(max_workers=16) as exe:\n            list(exe.map(read_file, files))\n        print(f'Loaded {len(files)} files in {time.time()-start:.1f}s\\n')\n    \n    def start_server(self):\n        cmd = [sys.executable, '-m', 'vllm.entrypoints.openai.api_server',\n               '--model', self.cfg.model_path,\n               '--served-model-name', self.cfg.served_model_name,\n               '--host', '0.0.0.0', '--port', str(self.cfg.server_port),\n               '--tensor-parallel-size', '1',\n               '--max-model-len', str(self.cfg.context_tokens),\n               '--gpu-memory-utilization', str(self.cfg.gpu_memory_utilization),\n               '--kv-cache-dtype', self.cfg.kv_cache_dtype,\n               '--disable-log-stats', '--enable-prefix-caching']\n        self.log_file = open('vllm_server.log', 'w')\n        return subprocess.Popen(cmd, stdout=self.log_file, stderr=subprocess.STDOUT)\n    \n    def wait_for_server(self, client, timeout=180):\n        print('Waiting for vLLM server...')\n        start = time.time()\n        for _ in range(timeout):\n            if self.server_process.poll() is not None:\n                raise RuntimeError('Server died')\n            try:\n                client.models.list()\n                print(f'Server ready in {time.time()-start:.1f}s\\n')\n                return\n            except: time.sleep(1)\n        raise RuntimeError('Server timeout')\n    \n    def stop_server(self):\n        if self.server_process: self.server_process.terminate(); self.server_process.wait()\n        if self.log_file: self.log_file.close()\n\nprint('Server manager defined')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.282987Z",
     "iopub.execute_input": "2026-02-03T01:13:47.283113Z",
     "iopub.status.idle": "2026-02-03T01:13:47.293092Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.283101Z",
     "shell.execute_reply": "2026-02-03T01:13:47.292723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Server manager defined\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 133
  },
  {
   "id": "kaggle_interface",
   "cell_type": "code",
   "source": "# ============================================================\n# KAGGLE INTERFACE\n# ============================================================\n\n_solver = None\n_server_manager = None\n\ndef initialize_solver():\n    global _solver, _server_manager\n    if _solver: return _solver\n    print('Initializing...')\n    _server_manager = ServerManager(CFG)\n    _server_manager.preload_model()\n    _server_manager.server_process = _server_manager.start_server()\n    _solver = ALGSolver(CFG)\n    temp_client = OpenAI(base_url=f'http://0.0.0.0:{CFG.server_port}/v1', api_key='sk-local')\n    _server_manager.wait_for_server(temp_client, CFG.server_timeout)\n    _solver.initialize()\n    return _solver\n\ndef predict(id_, question):\n    id_value = id_.item(0)\n    question_text = question.item(0)\n    print('\\n' + '='*60)\n    print(f'PROBLEM ID: {id_value}')\n    print('='*60)\n    solver = initialize_solver()\n    result = solver.solve(question_text)\n    answer = result.answer if result.answer else 0\n    print(f'\\nSUBMITTING: {answer}')\n    return pl.DataFrame({'id': id_value, 'answer': int(answer)})\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.293617Z",
     "iopub.execute_input": "2026-02-03T01:13:47.293741Z",
     "iopub.status.idle": "2026-02-03T01:13:47.350566Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.293730Z",
     "shell.execute_reply": "2026-02-03T01:13:47.350165Z"
    }
   },
   "outputs": [],
   "execution_count": 134
  },
  {
   "id": "main",
   "cell_type": "code",
   "source": "# ============================================================\n# MAIN\n# ============================================================\n\nif __name__ == '__main__' or True:\n    if os.path.exists('/kaggle'):\n        # Read reference.csv with only first 2 columns (id, problem)\n        import pandas as pd\n        ref_path = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv'\n        ref_df = pd.read_csv(ref_path, usecols=[0, 1])\n        ref_df.columns = ['id', 'question']\n        test_path = '/kaggle/working/test.csv'\n        ref_df.to_csv(test_path, index=False)\n        print(f'Using reference.csv: {len(ref_df)} problems')\n        \n        server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n        if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n            server.serve()\n        else:\n            server.run_local_gateway((test_path,))\n    else:\n        print('Not on Kaggle')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-03T01:13:47.351099Z",
     "iopub.execute_input": "2026-02-03T01:13:47.351225Z",
     "iopub.status.idle": "2026-02-03T01:15:16.333946Z",
     "shell.execute_reply.started": "2026-02-03T01:13:47.351214Z",
     "shell.execute_reply": "2026-02-03T01:15:16.333341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Using reference.csv: 10 problems\n\n============================================================\nPROBLEM ID: 42d360\n============================================================\nInitializing...\nLoading model from /kaggle/input/gpt-oss-120b/transformers/default/1...\nLoaded 26 files in 4.5s\n\nWaiting for vLLM server...\nServer ready in 0.0s\n\n[ALG] Initializing...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "[ColabKernelApp] WARNING | Eventloop or matplotlib integration failed. Is matplotlib installed?\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[LLM] Connecting to vLLM server...\n[LLM] Connected successfully\n[ALG] Ready\n============================================================\nPROBLEM: On a blackboard, Ken starts off by writing a positive integer $n$ and then appli...\n============================================================\n\n=== PHASE 1: PROBLEM CLASSIFICATION ===\n[ALG] Sending to LLM...\n[LLM] Generating (temp=0.3, max_tokens=500)...\n[LLM] Generated 2132 chars\n[ALG] Got response: 'analysisWe need to analyze the problem: It asks to find the maximum possible number of moves Ken cou'\n[ALG] Topic: algebra\n[ALG] Complexity: medium\n[ALG] Budget: 180s\n\n=== PHASE 2: LEMMA GRAPH ===\n[LLM] Generating (temp=0.5, max_tokens=2000)...\n[LLM] Generated 6230 chars\n[ALG] Graph: 1 lemmas\n[ALG] Order: ['FINAL']\n\n=== PHASE 3: SYNTHESIS ===\n[LLM] Generating (temp=0.7, max_tokens=4096)...\n[LLM] Generated 12584 chars\n[ALG] Answer: None, Time: 33.3s\n\nSUBMITTING: 0\n\n============================================================\nPROBLEM ID: dd7f5e\n============================================================\n============================================================\nPROBLEM: Let $\\mathcal{F}$ be the set of functions $\\alpha \\colon \\mathbb{Z}\\to \\mathbb{Z...\n============================================================\n\n=== PHASE 1: PROBLEM CLASSIFICATION ===\n[ALG] Sending to LLM...\n[LLM] Generating (temp=0.3, max_tokens=500)...\n[LLM] Generated 1600 chars\n[ALG] Got response: 'analysisWe need to analyze the problem: count the number of functions \u03b1: Z \u2192 Z with finite support ('\n[ALG] Topic: algebra\n[ALG] Complexity: medium\n[ALG] Budget: 180s\n\n=== PHASE 2: LEMMA GRAPH ===\n[LLM] Generating (temp=0.5, max_tokens=2000)...\n[LLM] Generated 6750 chars\n[ALG] Graph: 1 lemmas\n[ALG] Order: ['FINAL']\n\n=== PHASE 3: SYNTHESIS ===\n[LLM] Generating (temp=0.7, max_tokens=4096)...\n[LLM] Generated 12885 chars\n[ALG] Answer: None, Time: 33.2s\n\nSUBMITTING: 0\n\n============================================================\nPROBLEM ID: 92ba6a\n============================================================\n============================================================\nPROBLEM: Alice and Bob are each holding some integer number of sweets. Alice says to Bob:...\n============================================================\n\n=== PHASE 1: PROBLEM CLASSIFICATION ===\n[ALG] Sending to LLM...\n[LLM] Generating (temp=0.3, max_tokens=500)...\n[LLM] Generated 1587 chars\n[ALG] Got response: 'analysisWe need to analyze the problem. The problem is a word problem involving integer variables: A'\n[ALG] Topic: algebra\n[ALG] Complexity: medium\n[ALG] Budget: 180s\n\n=== PHASE 2: LEMMA GRAPH ===\n[LLM] Generating (temp=0.5, max_tokens=2000)...\n[LLM] Generated 5651 chars\n[ALG] Graph: 1 lemmas\n[ALG] Order: ['FINAL']\n\n=== PHASE 3: SYNTHESIS ===\n[LLM] Generating (temp=0.7, max_tokens=4096)...\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_106/3941729022.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not on Kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/templates.py\u001b[0m in \u001b[0;36mrun_local_gateway\u001b[0;34m(self, data_paths, file_share_dir, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gateway_for_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_share_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/base_gateway.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_data_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGatewayRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/base_gateway.py\u001b[0m in \u001b[0;36mget_all_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_batch_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_agnostic_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetition_specific_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/base_gateway.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_server_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/relay.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m    309\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_with_deadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/ai-mathematical-olympiad-progress-prize-3/kaggle_evaluation/core/relay.py\u001b[0m in \u001b[0;36m_send_with_deadline\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_made_first_connection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_deadline_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'StatusCode.DEADLINE_EXCEEDED'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     ) -> Any:\n\u001b[0;32m-> 1178\u001b[0;31m         state, call = self._blocking(\n\u001b[0m\u001b[1;32m   1179\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             )\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    },
    {
     "name": "stderr",
     "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1770081317.365463    1793 chttp2_transport.cc:1336] ipv6:%5B::1%5D:50051: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {http2_error:2, grpc_status:14}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 135
  }
 ]
}