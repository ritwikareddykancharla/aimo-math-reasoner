{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "sourceId": 118448,
     "databundleVersionId": 14559231,
     "sourceType": "competition"
    },
    {
     "sourceId": 289055161,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 510391,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 404485,
     "modelId": 422384
    }
   ],
   "dockerImageVersionId": 31260,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "intro",
   "cell_type": "markdown",
   "source": "# ALG Sequential Solver for AIMO3 - COMPLETE VERSION\n\nAdaptive Lemma Graph solver with domain knowledge:\n1. **Problem Classification** - Model determines topic and complexity\n2. **Topic-Specific DAG** - Build lemma graph based on problem type with domain knowledge\n3. **Dynamic Time Allocation** - Spend more time on hard problems\n4. **Sequential Traversal** - No parallel threads, one rigorous proof path\n5. **Domain Knowledge** - Algebra, Number Theory, Combinatorics, Geometry, Analysis\n\nStrategy:\n- Simple problems (2-3 lemmas): ~60 seconds\n- Medium problems (4-5 lemmas): ~180 seconds\n- Hard problems (6-8 lemmas): ~480 seconds",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "uninstall",
   "cell_type": "code",
   "source": "%pip uninstall --yes 'keras' 'matplotlib' 'scikit-learn' 'tensorflow' -q",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "setup",
   "cell_type": "code",
   "source": "import warnings\nwarnings.simplefilter('ignore')\n\nimport os\nimport sys\nimport subprocess\n\ndef set_env(input_archive, temp_dir):\n    if not os.path.exists(temp_dir):\n        os.makedirs(temp_dir, exist_ok=True)\n        subprocess.run(['tar', '-xzf', input_archive, '-C', temp_dir], check=True)\n    \n    subprocess.run([\n        sys.executable,\n        '-m',\n        'pip',\n        'install',\n        '--no-index',\n        '--find-links',\n        f'{temp_dir}/wheels',\n        'unsloth',\n        'trl',\n        'vllm',\n        'openai_harmony'\n    ], check=True, capture_output=True)\n\nset_env(\n    input_archive='/kaggle/input/aimo-3-utils/wheels.tar.gz',\n    temp_dir='/kaggle/tmp/setup'\n)\n\nos.environ['TRANSFORMERS_NO_TF'] = '1'\nos.environ['TRANSFORMERS_NO_FLAX'] = '1'\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nos.environ['TRITON_PTXAS_PATH'] = '/usr/local/cuda/bin/ptxas'\nos.environ['TIKTOKEN_ENCODINGS_BASE'] = '/kaggle/tmp/setup/tiktoken_encodings'\n\nprint('Environment setup complete')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "imports",
   "cell_type": "code",
   "source": "# ============================================================\n# IMPORTS\n# ============================================================\n\nimport gc\nimport re\nimport json\nimport math\nimport time\nimport queue\nimport threading\nimport contextlib\nimport traceback\nfrom typing import Optional, List, Dict, Tuple, Any\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict\nfrom enum import Enum\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nimport pandas as pd\nimport polars as pl\n\nfrom openai import OpenAI\n\nfrom openai_harmony import (\n    HarmonyEncodingName,\n    load_harmony_encoding,\n    SystemContent,\n    ReasoningEffort,\n    ToolNamespaceConfig,\n    Author,\n    Message,\n    Role,\n    TextContent,\n    Conversation\n)\n\nfrom transformers import set_seed\nimport kaggle_evaluation.aimo_3_inference_server\n\nprint('All imports done')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "config",
   "cell_type": "code",
   "source": "# ============================================================\n# CONFIGURATION WITH DOMAIN KNOWLEDGE\n# ============================================================\n\nclass CFG:\n    # Model settings\n    model_path = '/kaggle/input/gpt-oss-120b/transformers/default/1'\n    served_model_name = 'gpt-oss'\n    \n    # Inference settings\n    context_tokens = 65536\n    temperature = 0.7\n    top_p = 0.95\n    max_tokens_per_turn = 4096\n    \n    # Time budgets (seconds) based on complexity\n    time_budget = {\n        'simple': 60,\n        'medium': 180,\n        'hard': 480,\n        'default': 180\n    }\n    \n    # Lemma settings\n    max_lemmas = 8\n    max_retries_per_lemma = 3\n    \n    # Python sandbox\n    sandbox_timeout = 30\n    \n    # Server settings\n    server_port = 8000\n    server_timeout = 180\n    \n    # vLLM settings\n    kv_cache_dtype = 'fp8_e4m3'\n    dtype = 'auto'\n    gpu_memory_utilization = 0.96\n    batch_size = 256\n    \n    # Comprehensive domain knowledge for IMO problems\n    DOMAIN_KNOWLEDGE = {\n        'algebra': {\n            'description': 'Algebraic manipulation, equations, inequalities, polynomials',\n            'common_techniques': [\n                'Factorization and expansion',\n                'Substitution and change of variables',\n                'AM-GM inequality, Cauchy-Schwarz inequality',\n                \"Vieta's formulas for polynomials\",\n                'Symmetric sums and elementary symmetric polynomials',\n                'Telescoping sums and products',\n                'Completing the square',\n                'Functional equations',\n                'Inequalities (Chebyshev, Holder, Minkowski)'\n            ],\n            'common_patterns': [\n                'Look for symmetry in expressions',\n                'Consider substitution to simplify',\n                'Use inequalities to bound expressions',\n                'Factor polynomials to find roots',\n                'Look for telescoping patterns in sums'\n            ],\n            'verification_strategies': [\n                'Check with specific numerical examples',\n                'Verify inequalities at boundary cases',\n                'Test polynomial identities with random values',\n                'Use symbolic computation for expansions'\n            ]\n        },\n        'number_theory': {\n            'description': 'Properties of integers, divisibility, primes, modular arithmetic',\n            'common_techniques': [\n                'Modular arithmetic (mod n)',\n                'Chinese remainder theorem',\n                \"Fermat's little theorem and Euler's theorem\",\n                'Euclidean algorithm and Bezout identity',\n                'Prime factorization and unique factorization',\n                'Order of elements modulo n',\n                'Legendre symbol and quadratic reciprocity',\n                'Divisibility rules and properties',\n                'Pell equations and Diophantine equations'\n            ],\n            'common_patterns': [\n                'Check parity (even/odd)',\n                'Consider remainders modulo small numbers',\n                'Look for prime factorization patterns',\n                'Use divisibility chains',\n                'Consider greatest common divisors'\n            ],\n            'verification_strategies': [\n                'Test with small numerical examples',\n                'Verify divisibility properties',\n                'Check modular arithmetic calculations',\n                'Use brute force for small ranges'\n            ]\n        },\n        'combinatorics': {\n            'description': 'Counting, arrangements, graphs, combinatorial structures',\n            'common_techniques': [\n                'Pigeonhole principle',\n                'Double counting arguments',\n                'Inclusion-exclusion principle',\n                'Generating functions',\n                'Recurrence relations',\n                'Graph theory concepts',\n                'Bijections and combinatorial proofs',\n                'Ramsey theory',\n                'Probabilistic method'\n            ],\n            'common_patterns': [\n                'Look for invariant quantities',\n                'Consider extreme cases',\n                'Use symmetry to simplify counting',\n                'Look for recursive structure',\n                'Consider graph representations'\n            ],\n            'verification_strategies': [\n                'Count small cases manually',\n                'Verify recurrence relations',\n                'Check combinatorial identities',\n                'Use computational enumeration for small n'\n            ]\n        },\n        'geometry': {\n            'description': 'Shapes, angles, lengths, coordinates, transformations',\n            'common_techniques': [\n                'Coordinate geometry',\n                'Vector methods',\n                'Trigonometry and trigonometric identities',\n                'Similarity and congruence',\n                'Power of a point',\n                'Circle theorems (inscribed angles, cyclic quadrilaterals)',\n                'Triangle geometry (cevians, medians, altitudes)',\n                'Transformations (rotations, reflections, homothety)',\n                'Complex numbers in geometry'\n            ],\n            'common_patterns': [\n                'Add auxiliary lines',\n                'Use coordinate system wisely',\n                'Look for similar triangles',\n                'Consider symmetry',\n                'Use angle chasing'\n            ],\n            'verification_strategies': [\n                'Verify with specific coordinates',\n                'Check trigonometric identities',\n                'Use geometric software for verification',\n                'Test with special cases'\n            ]\n        },\n        'analysis': {\n            'description': 'Limits, continuity, sequences, series, inequalities',\n            'common_techniques': [\n                'Epsilon-delta arguments',\n                'Mean value theorem and Taylor series',\n                'Monotonic sequences and convergence',\n                'Inequalities (Jensen, Chebyshev, rearrangement)',\n                'Functional equations',\n                'Recurrence relations for sequences',\n                'Asymptotic analysis',\n                'Fixed point theorems',\n                'Continuity and intermediate value property'\n            ],\n            'common_patterns': [\n                'Look for monotonicity',\n                'Consider limiting behavior',\n                'Use telescoping in sequences',\n                'Apply known inequalities',\n                'Check special values'\n            ],\n            'verification_strategies': [\n                'Test with numerical sequences',\n                'Verify inequalities numerically',\n                'Check continuity at sample points',\n                'Use computational limits'\n            ]\n        }\n    }\n    \n    # Common IMO problem solving strategies\n    IMO_STRATEGIES = [\n        'Look for invariant or monovariant quantities',\n        'Consider extreme cases or boundary conditions',\n        'Use symmetry to reduce complexity',\n        'Try small cases to find pattern',\n        'Assume opposite and seek contradiction',\n        'Use induction (mathematical, strong, or structural)',\n        'Apply probabilistic method',\n        'Construct explicit examples or counterexamples',\n        'Use double counting arguments',\n        'Employ generating functions or recurrence relations'\n    ]\n\nset_seed(42)\nprint('Configuration with domain knowledge loaded')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "prompts",
   "cell_type": "code",
   "source": "# ============================================================\n# JSON OUTPUT PROMPTS WITH DOMAIN KNOWLEDGE\n# ============================================================\n\nCLASSIFICATION_PROMPT = \"\"\"You are an expert IMO problem classifier. Analyze this mathematical problem and output ONLY valid JSON.\n\nProblem: {problem}\n\nDomain Knowledge Context:\n{domain_context}\n\nOutput JSON format:\n{{\n  \"topic\": \"algebra|number_theory|combinatorics|geometry|analysis\",\n  \"complexity\": \"simple|medium|hard\",\n  \"key_techniques\": [\"technique1\", \"technique2\", \"technique3\"],\n  \"estimated_lemmas\": 4,\n  \"reasoning\": \"brief explanation\",\n  \"confidence\": 0.95\n}}\n\nGuidelines:\n- Simple: Direct, few steps (< 5 min for expert)\n- Medium: Requires insight, multiple steps (5-15 min)\n- Hard: Deep insight, creative approach (> 15 min)\n- Choose techniques from domain knowledge\n- Confidence between 0.0 and 1.0\n\"\"\"\n\nLEMMA_GRAPH_PROMPT = \"\"\"You are an IMO Gold Medalist. Decompose this problem into a lemma graph. Output ONLY valid JSON.\n\nProblem: {problem}\nTopic: {topic}\nComplexity: {complexity}\nTarget Lemma Count: {estimated_lemmas}\n\nDomain Knowledge for {topic}:\n{domain_knowledge}\n\nIMO Strategies to Consider:\n{imo_strategies}\n\nOutput JSON format:\n{{\n  \"lemmas\": [\n    {{\n      \"id\": \"L1\",\n      \"statement\": \"mathematical statement\",\n      \"type\": \"structural|reduction|computational|inequality|existence|counting|verification\",\n      \"dependencies\": [],\n      \"purpose\": \"why this lemma is needed\",\n      \"verification_strategy\": \"how to verify this lemma\",\n      \"domain_hint\": \"which domain technique applies\"\n    }},\n    ...\n  ],\n  \"final_lemma\": {{\n    \"id\": \"FINAL\",\n    \"statement\": \"Synthesize solution from all lemmas\",\n    \"type\": \"synthesis\",\n    \"dependencies\": [\"L1\", \"L2\", ...],\n    \"purpose\": \"Combine verified lemmas to solve original problem\"\n  }},\n  \"graph_strategy\": \"explanation of decomposition approach\"\n}}\n\nRules:\n1. Dependencies must form a DAG (no cycles)\n2. Use domain-appropriate techniques\n3. Each lemma should be mathematically precise\n4. Consider IMO problem-solving strategies\n\"\"\"\n\nLEMMA_PROOF_PROMPT = \"\"\"You are a mathematical proof assistant. Prove this lemma and provide verification. Output ONLY valid JSON.\n\nProblem Context: {problem}\nLemma ID: {lemma_id}\nLemma Statement: {lemma_statement}\nLemma Type: {lemma_type}\nPurpose: {purpose}\n\nDomain: {topic}\nDomain Techniques: {domain_techniques}\n\nOutput JSON format:\n{{\n  \"proof\": \"step-by-step mathematical proof\",\n  \"verification_code\": \"python code to verify (if applicable, else empty string)\",\n  \"verification_explanation\": \"how verification works\",\n  \"confidence\": 0.95,\n  \"key_insights\": [\"insight1\", \"insight2\"]\n}}\n\nGuidelines:\n- Proof must be mathematically rigorous\n- Include all necessary steps\n- If computational lemma, provide Python code\n- If theoretical lemma, explain verification strategy\n- Confidence based on proof completeness\n\"\"\"\n\nSOLUTION_PROMPT = \"\"\"You are an IMO Gold Medalist. Solve this problem using the verified lemmas. Output ONLY valid JSON.\n\nProblem: {problem}\n\nDomain: {topic}\nDomain Knowledge: {domain_knowledge}\n\nVerified Lemmas Summary:\n{lemmas_summary}\n\nOutput JSON format:\n{{\n  \"solution_analysis\": \"how lemmas combine to solve problem\",\n  \"step_by_step_solution\": \"complete mathematical solution\",\n  \"answer\": 123,\n  \"confidence\": 0.95,\n  \"verification_checks\": [\"check1\", \"check2\"],\n  \"alternative_approaches\": [\"approach1\", \"approach2\"]\n}}\n\nRules:\n1. Answer must be an integer (or 0 if unknown)\n2. Confidence between 0.0 and 1.0\n3. Show how lemmas are used\n4. Include verification of answer\n5. Consider edge cases\n\"\"\"\n\nDIRECT_SOLUTION_PROMPT = \"\"\"You are an IMO Gold Medalist. Solve this problem directly. Output ONLY valid JSON.\n\nProblem: {problem}\nTopic: {topic}\n\nDomain Knowledge for {topic}:\n{domain_knowledge}\n\nIMO Strategies:\n{imo_strategies}\n\nOutput JSON format:\n{{\n  \"problem_analysis\": \"understanding of problem structure\",\n  \"solution_strategy\": \"chosen approach and why\",\n  \"mathematical_proof\": \"complete rigorous proof\",\n  \"answer\": 123,\n  \"confidence\": 0.95,\n  \"verification\": \"how answer was verified\",\n  \"edge_cases_checked\": [\"case1\", \"case2\"]\n}}\n\nRules:\n1. Provide complete mathematical proof\n2. Answer must be an integer\n3. Confidence between 0.0 and 1.0\n4. Check all edge cases\n5. Verify answer makes sense\n\"\"\"\n\nprint('Prompts with domain knowledge defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "data_structures",
   "cell_type": "code",
   "source": "# ============================================================\n# SIMPLE DATA STRUCTURES\n# ============================================================\n\n@dataclass\nclass ProblemClassification:\n    topic: str\n    complexity: str  # \"simple\", \"medium\", \"hard\"\n    key_techniques: List[str] = field(default_factory=list)\n    estimated_lemmas: int = 4\n    reasoning: str = ''\n    confidence: float = 0.0\n    \n    def get_time_budget(self) -> float:\n        return CFG.time_budget.get(self.complexity, CFG.time_budget['default'])\n    \n    def get_domain_info(self) -> Dict:\n        \"\"\"Get domain knowledge for this topic\"\"\"\n        return CFG.DOMAIN_KNOWLEDGE.get(self.topic, CFG.DOMAIN_KNOWLEDGE['algebra'])\n\n@dataclass\nclass Lemma:\n    id: str\n    statement: str\n    lemma_type: str\n    dependencies: List[str] = field(default_factory=list)\n    purpose: str = ''\n    verification_strategy: str = ''\n    domain_hint: str = ''\n    proof: str = ''\n    verification_code: str = ''\n    execution_result: Optional[str] = None\n    verified: bool = False\n    confidence: float = 0.0\n    \n    def to_summary(self) -> str:\n        status = \"\u2713\" if self.verified else \"?\"\n        return f\"{status} {self.id} ({self.lemma_type}): {self.statement[:80]}...\"\n\n@dataclass \nclass LemmaGraph:\n    problem: str\n    classification: ProblemClassification\n    lemmas: Dict[str, Lemma] = field(default_factory=dict)\n    final_lemma: Optional[Lemma] = None\n    graph_strategy: str = ''\n    \n    def get_dependency_order(self) -> List[str]:\n        \"\"\"Topological sort of lemmas\"\"\"\n        if not self.lemmas:\n            return []\n        \n        # Build adjacency and in-degree\n        adj = {lid: [] for lid in self.lemmas}\n        in_deg = {lid: 0 for lid in self.lemmas}\n        \n        for lemma in self.lemmas.values():\n            for dep in lemma.dependencies:\n                if dep in self.lemmas:\n                    adj[dep].append(lemma.id)\n                    in_deg[lemma.id] += 1\n        \n        # Start with nodes having no dependencies\n        queue = [lid for lid, deg in in_deg.items() if deg == 0]\n        result = []\n        \n        while queue:\n            lid = queue.pop(0)\n            result.append(lid)\n            \n            for neighbor in adj[lid]:\n                in_deg[neighbor] -= 1\n                if in_deg[neighbor] == 0:\n                    queue.append(neighbor)\n        \n        if len(result) != len(self.lemmas):\n            # Fallback: return in ID order\n            return sorted(self.lemmas.keys())\n        \n        return result\n    \n    def get_lemma_summary(self) -> str:\n        \"\"\"Create formatted summary of all lemmas\"\"\"\n        summary_lines = []\n        for lemma_id in self.get_dependency_order():\n            lemma = self.lemmas[lemma_id]\n            summary_lines.append(lemma.to_summary())\n        return \"\\n\".join(summary_lines)\n\n@dataclass\nclass SolutionResult:\n    problem: str\n    classification: ProblemClassification\n    answer: Optional[int] = None\n    success: bool = False\n    time_taken: float = 0.0\n    method: str = 'unknown'\n    confidence: float = 0.0\n    solution_text: str = ''\n\nprint('Data structures defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "json_parser",
   "cell_type": "code",
   "source": "# ============================================================\n# JSON PARSING UTILITIES\n# ============================================================\n\nclass JSONParser:\n    @staticmethod\n    def parse_json_response(text: str, fallback=None):\n        \"\"\"Try to parse JSON from text, with fallback\"\"\"\n        if not text:\n            return fallback\n        \n        # Try to extract JSON from text\n        try:\n            # Look for JSON pattern\n            json_pattern = r'\\{.*\\}'\n            match = re.search(json_pattern, text, re.DOTALL)\n            if match:\n                json_str = match.group(0)\n                return json.loads(json_str)\n            \n            # If no match, try parsing entire text\n            return json.loads(text)\n        except json.JSONDecodeError as e:\n            print(f\"[WARNING] JSON parse error: {e}\")\n            print(f\"[DEBUG] Text snippet: {text[:200]}...\")\n            return fallback\n    \n    @staticmethod\n    def parse_classification(text: str) -> ProblemClassification:\n        \"\"\"Parse classification from JSON response\"\"\"\n        data = JSONParser.parse_json_response(text)\n        if not data:\n            return ProblemClassification(\n                topic='algebra',\n                complexity='medium',\n                confidence=0.5\n            )\n        \n        return ProblemClassification(\n            topic=data.get('topic', 'algebra'),\n            complexity=data.get('complexity', 'medium'),\n            key_techniques=data.get('key_techniques', []),\n            estimated_lemmas=data.get('estimated_lemmas', 4),\n            reasoning=data.get('reasoning', ''),\n            confidence=data.get('confidence', 0.5)\n        )\n    \n    @staticmethod\n    def parse_lemma_graph(text: str, problem: str, classification: ProblemClassification) -> LemmaGraph:\n        \"\"\"Parse lemma graph from JSON response\"\"\"\n        data = JSONParser.parse_json_response(text)\n        if not data:\n            # Create simple default graph\n            graph = LemmaGraph(problem, classification)\n            graph.lemmas['L1'] = Lemma(\n                id='L1',\n                statement='Understand problem structure',\n                lemma_type='structural'\n            )\n            graph.final_lemma = Lemma(\n                id='FINAL',\n                statement='Solve the problem',\n                lemma_type='synthesis',\n                dependencies=['L1']\n            )\n            return graph\n        \n        graph = LemmaGraph(problem, classification)\n        graph.graph_strategy = data.get('graph_strategy', '')\n        \n        # Parse lemmas\n        lemmas_data = data.get('lemmas', [])\n        for lemma_data in lemmas_data:\n            lemma = Lemma(\n                id=lemma_data.get('id', f'L{len(graph.lemmas) + 1}'),\n                statement=lemma_data.get('statement', ''),\n                lemma_type=lemma_data.get('type', 'structural'),\n                dependencies=lemma_data.get('dependencies', []),\n                purpose=lemma_data.get('purpose', ''),\n                verification_strategy=lemma_data.get('verification_strategy', ''),\n                domain_hint=lemma_data.get('domain_hint', '')\n            )\n            graph.lemmas[lemma.id] = lemma\n        \n        # Parse final lemma\n        final_data = data.get('final_lemma', {})\n        graph.final_lemma = Lemma(\n            id=final_data.get('id', 'FINAL'),\n            statement=final_data.get('statement', 'Synthesize solution'),\n            lemma_type=final_data.get('type', 'synthesis'),\n            dependencies=final_data.get('dependencies', list(graph.lemmas.keys())),\n            purpose=final_data.get('purpose', 'Combine all lemmas')\n        )\n        \n        return graph\n    \n    @staticmethod\n    def parse_lemma_proof(text: str) -> Dict:\n        \"\"\"Parse lemma proof from JSON response\"\"\"\n        data = JSONParser.parse_json_response(text, {})\n        return {\n            'proof': data.get('proof', ''),\n            'verification_code': data.get('verification_code', ''),\n            'verification_explanation': data.get('verification_explanation', ''),\n            'confidence': data.get('confidence', 0.5),\n            'key_insights': data.get('key_insights', [])\n        }\n    \n    @staticmethod\n    def parse_solution(text: str) -> Dict:\n        \"\"\"Parse solution from JSON response\"\"\"\n        data = JSONParser.parse_json_response(text, {})\n        return {\n            'solution_analysis': data.get('solution_analysis', ''),\n            'step_by_step_solution': data.get('step_by_step_solution', ''),\n            'answer': data.get('answer', 0),\n            'confidence': data.get('confidence', 0.0),\n            'verification_checks': data.get('verification_checks', []),\n            'alternative_approaches': data.get('alternative_approaches', [])\n        }\n\nprint('JSON Parser defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "sandbox",
   "cell_type": "code",
   "source": "# ============================================================\n# JUPYTER SANDBOX\n# ============================================================\n\nfrom jupyter_client import KernelManager\n\nclass ALGSandbox:\n    _port_lock = threading.Lock()\n    _next_port = 50000\n    \n    @classmethod\n    def _get_next_ports(cls, count=5):\n        with cls._port_lock:\n            ports = list(range(cls._next_port, cls._next_port + count))\n            cls._next_port += count\n            return ports\n    \n    def __init__(self, timeout=30.0):\n        self.timeout = timeout\n        ports = self._get_next_ports(5)\n        env = os.environ.copy()\n        env['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n        env['PYTHONWARNINGS'] = 'ignore'\n        \n        self._km = KernelManager()\n        self._km.shell_port = ports[0]\n        self._km.iopub_port = ports[1]\n        self._km.stdin_port = ports[2]\n        self._km.hb_port = ports[3]\n        self._km.control_port = ports[4]\n        \n        try:\n            self._km.start_kernel(env=env)\n            self._client = self._km.blocking_client()\n            self._client.start_channels()\n            self._client.wait_for_ready(timeout=30)\n            \n            # Initialize with math and sympy\n            init_code = \"\"\"import math\nimport sympy as sp\nimport itertools\nimport numpy as np\nimport random\nfrom fractions import Fraction\nfrom collections import defaultdict, Counter\"\"\"\n            self.execute(init_code)\n        except Exception as e:\n            print(f\"[WARNING] Sandbox initialization failed: {e}\")\n            self._km = None\n            self._client = None\n    \n    def execute(self, code, timeout=None):\n        if not self._client:\n            return {'success': False, 'output': '', 'error': 'Sandbox not initialized'}\n        \n        timeout = timeout or self.timeout\n        try:\n            msg_id = self._client.execute(code, store_history=False)\n            stdout, stderr = [], []\n            start = time.time()\n            \n            while True:\n                if time.time() - start > timeout:\n                    self._km.interrupt_kernel()\n                    return {'success': False, 'output': '', 'error': 'Timeout'}\n                \n                try:\n                    msg = self._client.get_iopub_msg(timeout=1.0)\n                except Exception:\n                    continue\n                \n                if msg.get('parent_header', {}).get('msg_id') != msg_id:\n                    continue\n                \n                msg_type = msg.get('msg_type')\n                content = msg.get('content', {})\n                \n                if msg_type == 'stream':\n                    text = content.get('text', '')\n                    if content.get('name') == 'stdout':\n                        stdout.append(text)\n                    else:\n                        stderr.append(text)\n                elif msg_type == 'error':\n                    stderr.append('\\n'.join(content.get('traceback', [])))\n                elif msg_type == 'status' and content.get('execution_state') == 'idle':\n                    break\n            \n            stdout, stderr = ''.join(stdout), ''.join(stderr)\n            if stderr:\n                return {'success': False, 'output': stdout, 'error': stderr}\n            return {'success': True, 'output': stdout.strip(), 'error': None}\n            \n        except Exception as e:\n            return {'success': False, 'output': '', 'error': str(e)}\n    \n    def close(self):\n        if self._client:\n            try:\n                self._client.stop_channels()\n            except:\n                pass\n        if self._km:\n            try:\n                self._km.shutdown_kernel(now=True)\n            except:\n                pass\n\nprint('Sandbox defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "llm_interface",
   "cell_type": "code",
   "source": "# ============================================================\n# LLM INTERFACE\n# ============================================================\n\nclass LLMInterface:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.base_url = f'http://0.0.0.0:{cfg.server_port}/v1'\n        self.api_key = 'sk-local'\n        self.client = None\n        self.encoding = None\n    \n    def initialize(self):\n        print('[LLM] Connecting to vLLM server...', flush=True)\n        retries = 3\n        for i in range(retries):\n            try:\n                self.client = OpenAI(base_url=self.base_url, api_key=self.api_key, timeout=300)\n                self.encoding = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n                print('[LLM] Connected successfully', flush=True)\n                return\n            except Exception as e:\n                if i == retries - 1:\n                    raise\n                print(f'[LLM] Connection attempt {i+1} failed: {e}')\n                time.sleep(5)\n    \n    def generate(self, system_prompt, user_prompt, temperature=None, max_tokens=None):\n        temp = temperature or self.cfg.temperature\n        max_tok = max_tokens or self.cfg.max_tokens_per_turn\n        \n        if not self.client:\n            raise RuntimeError('LLM client not initialized!')\n        \n        try:\n            system_content = (SystemContent.new()\n                .with_model_identity(system_prompt)\n                .with_reasoning_effort(reasoning_effort=ReasoningEffort.HIGH))\n            \n            system_msg = Message.from_role_and_content(Role.SYSTEM, system_content)\n            user_msg = Message.from_role_and_content(Role.USER, TextContent(text=user_prompt))\n            conversation = Conversation.from_messages([system_msg, user_msg])\n            \n            if self.encoding:\n                prompt_ids = self.encoding.render_conversation_for_completion(conversation, Role.ASSISTANT)\n            else:\n                # Fallback\n                prompt_text = f\"System: {system_prompt}\\n\\nUser: {user_prompt}\\n\\nAssistant:\"\n                prompt_ids = prompt_text\n            \n            response = self.client.completions.create(\n                model=self.cfg.served_model_name,\n                temperature=temp,\n                max_tokens=max_tok,\n                prompt=prompt_ids,\n                stop=None)\n            \n            result = response.choices[0].text.strip()\n            return result\n            \n        except Exception as e:\n            print(f'[LLM] Generation error: {e}')\n            return ''\n\nprint('LLM Interface defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "alg_solver",
   "cell_type": "code",
   "source": "# ============================================================\n# IMPROVED ALG SOLVER\n# ============================================================\n\nclass ALGSolver:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.llm = LLMInterface(cfg)\n        self.sandbox = None\n        self.parser = JSONParser()\n    \n    def initialize(self):\n        print('[ALG] Initializing...')\n        sys.stdout.flush()\n        self.sandbox = ALGSandbox(timeout=self.cfg.sandbox_timeout)\n        self.llm.initialize()\n        print('[ALG] Ready')\n        sys.stdout.flush()\n    \n    def get_domain_context(self, topic):\n        \"\"\"Get formatted domain context for prompts\"\"\"\n        domain_info = CFG.DOMAIN_KNOWLEDGE.get(topic, CFG.DOMAIN_KNOWLEDGE['algebra'])\n        \n        context = f\"Topic: {topic}\\n\"\n        context += f\"Description: {domain_info['description']}\\n\\n\"\n        context += \"Common Techniques:\\n\"\n        for i, technique in enumerate(domain_info['common_techniques'][:5], 1):\n            context += f\"{i}. {technique}\\n\"\n        \n        context += \"\\nCommon Patterns:\\n\"\n        for i, pattern in enumerate(domain_info['common_patterns'][:3], 1):\n            context += f\"{i}. {pattern}\\n\"\n        \n        return context\n    \n    def get_imo_strategies(self):\n        \"\"\"Get formatted IMO strategies\"\"\"\n        strategies = \"IMO Problem Solving Strategies:\\n\"\n        for i, strategy in enumerate(CFG.IMO_STRATEGIES[:5], 1):\n            strategies += f\"{i}. {strategy}\\n\"\n        return strategies\n    \n    def classify_problem(self, problem):\n        print('\\n=== PHASE 1: PROBLEM CLASSIFICATION ===')\n        \n        # Get general domain context for classification\n        domain_context = \"Available Domains:\\n\"\n        for topic, info in CFG.DOMAIN_KNOWLEDGE.items():\n            domain_context += f\"- {topic}: {info['description'][:100]}...\\n\"\n        \n        prompt = CLASSIFICATION_PROMPT.format(\n            problem=problem,\n            domain_context=domain_context\n        )\n        \n        response = self.llm.generate(\n            system_prompt=\"You are an expert IMO problem classifier. Output ONLY valid JSON.\",\n            user_prompt=prompt,\n            temperature=0.3,\n            max_tokens=500\n        )\n        \n        print(f'[ALG] Classification response: {response[:200]}...')\n        \n        classification = self.parser.parse_classification(response)\n        \n        print(f'[ALG] Topic: {classification.topic}')\n        print(f'[ALG] Complexity: {classification.complexity}')\n        print(f'[ALG] Estimated lemmas: {classification.estimated_lemmas}')\n        print(f'[ALG] Confidence: {classification.confidence:.2f}')\n        print(f'[ALG] Budget: {classification.get_time_budget()}s')\n        \n        return classification\n    \n    def build_lemma_graph(self, problem, classification):\n        print('\\n=== PHASE 2: LEMMA GRAPH CONSTRUCTION ===')\n        \n        domain_knowledge = self.get_domain_context(classification.topic)\n        imo_strategies = self.get_imo_strategies()\n        \n        prompt = LEMMA_GRAPH_PROMPT.format(\n            problem=problem,\n            topic=classification.topic,\n            complexity=classification.complexity,\n            estimated_lemmas=classification.estimated_lemmas,\n            domain_knowledge=domain_knowledge,\n            imo_strategies=imo_strategies\n        )\n        \n        response = self.llm.generate(\n            system_prompt=\"You are an IMO Gold Medalist decomposing problems into lemma graphs. Output ONLY valid JSON.\",\n            user_prompt=prompt,\n            temperature=0.5,\n            max_tokens=2000\n        )\n        \n        print(f'[ALG] Lemma graph response: {response[:300]}...')\n        \n        graph = self.parser.parse_lemma_graph(response, problem, classification)\n        \n        print(f'[ALG] Graph created: {len(graph.lemmas)} lemmas + final')\n        print(f'[ALG] Dependencies: {graph.get_dependency_order()}')\n        \n        return graph\n    \n    def verify_lemma(self, lemma, problem, classification):\n        \"\"\"Verify a single lemma with proof and code execution\"\"\"\n        print(f'[ALG] Verifying lemma {lemma.id}: {lemma.lemma_type}')\n        \n        domain_info = classification.get_domain_info()\n        domain_techniques = \"\\n\".join(domain_info.get('common_techniques', [])[:3])\n        \n        prompt = LEMMA_PROOF_PROMPT.format(\n            problem=problem,\n            lemma_id=lemma.id,\n            lemma_statement=lemma.statement,\n            lemma_type=lemma.lemma_type,\n            purpose=lemma.purpose,\n            topic=classification.topic,\n            domain_techniques=domain_techniques\n        )\n        \n        response = self.llm.generate(\n            system_prompt=\"You are a mathematical proof assistant. Output ONLY valid JSON.\",\n            user_prompt=prompt,\n            temperature=0.3,\n            max_tokens=1500\n        )\n        \n        proof_data = self.parser.parse_lemma_proof(response)\n        \n        lemma.proof = proof_data.get('proof', '')\n        lemma.verification_code = proof_data.get('verification_code', '')\n        lemma.confidence = proof_data.get('confidence', 0.5)\n        \n        # Try to execute verification code if provided\n        if lemma.verification_code and self.sandbox:\n            print(f'[ALG] Executing verification code for {lemma.id}')\n            result = self.sandbox.execute(lemma.verification_code)\n            lemma.execution_result = f\"Output: {result.get('output', '')}\\nError: {result.get('error', '')}\"\n            lemma.verified = result.get('success', False)\n            \n            if lemma.verified:\n                print(f'[ALG] \u2713 Lemma {lemma.id} verified')\n            else:\n                print(f'[ALG] \u2717 Lemma {lemma.id} verification failed')\n        else:\n            # For theoretical lemmas, assume verified if proof seems reasonable\n            lemma.verified = len(lemma.proof) > 100  # Simple heuristic\n            print(f'[ALG] {\"\u2713\" if lemma.verified else \"\u2717\"} Lemma {lemma.id} (theoretical)')\n        \n        return lemma.verified\n    \n    def solve_via_lemmas(self, problem, classification, graph):\n        \"\"\"Solve problem using lemma graph approach\"\"\"\n        print('\\n=== PHASE 3: LEMMA VERIFICATION ===')\n        \n        # Verify lemmas in dependency order\n        verified_count = 0\n        lemma_order = graph.get_dependency_order()\n        \n        for lemma_id in lemma_order:\n            if lemma_id == 'FINAL':\n                continue\n                \n            lemma = graph.lemmas[lemma_id]\n            if self.verify_lemma(lemma, problem, classification):\n                verified_count += 1\n            \n            # Check time budget\n            # (Time check would go here)\n        \n        print(f'[ALG] Verified {verified_count}/{len(graph.lemmas)} lemmas')\n        \n        # Generate solution using verified lemmas\n        print('\\n=== PHASE 4: SOLUTION SYNTHESIS ===')\n        \n        lemmas_summary = graph.get_lemma_summary()\n        domain_knowledge = self.get_domain_context(classification.topic)\n        \n        prompt = SOLUTION_PROMPT.format(\n            problem=problem,\n            topic=classification.topic,\n            domain_knowledge=domain_knowledge,\n            lemmas_summary=lemmas_summary\n        )\n        \n        response = self.llm.generate(\n            system_prompt=\"You are an IMO Gold Medalist solving problems. Output ONLY valid JSON.\",\n            user_prompt=prompt,\n            temperature=0.3,\n            max_tokens=2000\n        )\n        \n        solution_data = self.parser.parse_solution(response)\n        \n        return solution_data\n    \n    def solve_directly(self, problem, classification):\n        \"\"\"Fallback: Solve problem directly without lemma graph\"\"\"\n        print('\\n=== DIRECT SOLUTION (FALLBACK) ===')\n        \n        domain_knowledge = self.get_domain_context(classification.topic)\n        imo_strategies = self.get_imo_strategies()\n        \n        prompt = DIRECT_SOLUTION_PROMPT.format(\n            problem=problem,\n            topic=classification.topic,\n            domain_knowledge=domain_knowledge,\n            imo_strategies=imo_strategies\n        )\n        \n        response = self.llm.generate(\n            system_prompt=\"You are an IMO Gold Medalist solving problems. Output ONLY valid JSON.\",\n            user_prompt=prompt,\n            temperature=0.3,\n            max_tokens=2000\n        )\n        \n        solution_data = self.parser.parse_solution(response)\n        return solution_data\n    \n    def solve(self, problem):\n        \"\"\"Main entry point for solving a problem\"\"\"\n        start_time = time.time()\n        print('\\n' + '='*60)\n        print(f'PROBLEM: {problem[:100]}...')\n        print('='*60)\n        \n        try:\n            # Phase 1: Classification\n            classification = self.classify_problem(problem)\n            time_budget = classification.get_time_budget()\n            print(f'[ALG] Time budget: {time_budget}s')\n            \n            # Phase 2 & 3: Build and verify lemma graph\n            graph = self.build_lemma_graph(problem, classification)\n            \n            # Check if we have a valid lemma graph\n            if len(graph.lemmas) > 0:\n                solution_data = self.solve_via_lemmas(problem, classification, graph)\n                method = 'lemma_graph'\n            else:\n                # Fallback to direct solution\n                solution_data = self.solve_directly(problem, classification)\n                method = 'direct'\n            \n            # Extract answer\n            answer = solution_data.get('answer', 0)\n            confidence = solution_data.get('confidence', 0.0)\n            \n            elapsed = time.time() - start_time\n            print(f'[ALG] Answer: {answer}, Confidence: {confidence:.2f}, Time: {elapsed:.1f}s')\n            \n            return SolutionResult(\n                problem=problem,\n                classification=classification,\n                answer=answer,\n                success=answer is not None and answer != 0,\n                time_taken=elapsed,\n                method=method,\n                confidence=confidence,\n                solution_text=solution_data.get('step_by_step_solution', '')\n            )\n            \n        except Exception as e:\n            print(f'[ALG] ERROR: {e}')\n            traceback.print_exc()\n            return SolutionResult(\n                problem=problem,\n                classification=ProblemClassification('unknown', 'medium'),\n                answer=0,\n                success=False,\n                time_taken=time.time() - start_time,\n                method='error'\n            )\n\nprint('ALG Solver defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "server_manager",
   "cell_type": "code",
   "source": "# ============================================================\n# SERVER MANAGER\n# ============================================================\n\nclass ServerManager:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.server_process = None\n        self.log_file = None\n    \n    def preload_model(self):\n        print(f'[Server] Preloading model from {self.cfg.model_path}...')\n        start = time.time()\n        files = []\n        for root, _, fs in os.walk(self.cfg.model_path):\n            for f in fs:\n                path = os.path.join(root, f)\n                if os.path.isfile(path):\n                    files.append(path)\n        \n        def read_file(path):\n            with open(path, 'rb') as f:\n                while f.read(1024 * 1024 * 1024):\n                    pass\n        \n        with ThreadPoolExecutor(max_workers=16) as exe:\n            list(exe.map(read_file, files))\n        \n        print(f'[Server] Loaded {len(files)} files in {time.time()-start:.1f}s')\n    \n    def start_server(self):\n        cmd = [\n            sys.executable, '-m', 'vllm.entrypoints.openai.api_server',\n            '--model', self.cfg.model_path,\n            '--served-model-name', self.cfg.served_model_name,\n            '--host', '0.0.0.0',\n            '--port', str(self.cfg.server_port),\n            '--tensor-parallel-size', '1',\n            '--max-model-len', str(self.cfg.context_tokens),\n            '--gpu-memory-utilization', str(self.cfg.gpu_memory_utilization),\n            '--kv-cache-dtype', self.cfg.kv_cache_dtype,\n            '--disable-log-stats',\n            '--enable-prefix-caching'\n        ]\n        self.log_file = open('vllm_server.log', 'w')\n        return subprocess.Popen(cmd, stdout=self.log_file, stderr=subprocess.STDOUT)\n    \n    def wait_for_server(self, client, timeout=180):\n        print('[Server] Waiting for vLLM server...')\n        start = time.time()\n        for _ in range(timeout):\n            if self.server_process.poll() is not None:\n                raise RuntimeError('Server died')\n            try:\n                client.models.list()\n                print(f'[Server] Ready in {time.time()-start:.1f}s')\n                return\n            except Exception:\n                time.sleep(1)\n        raise TimeoutError('Server failed to start')\n    \n    def cleanup(self):\n        if self.server_process:\n            self.server_process.terminate()\n            try:\n                self.server_process.wait(timeout=10)\n            except subprocess.TimeoutExpired:\n                self.server_process.kill()\n        if self.log_file:\n            self.log_file.close()\n\nprint('Server Manager defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "kaggle_interface",
   "cell_type": "code",
   "source": "# ============================================================\n# KAGGLE INTERFACE\n# ============================================================\n\n_solver = None\n_server_manager = None\n\ndef initialize_solver():\n    global _solver, _server_manager\n    if _solver is not None:\n        return _solver\n    \n    print('[Kaggle] Initializing ALG solver...')\n    _server_manager = ServerManager(CFG)\n    _server_manager.preload_model()\n    _server_manager.server_process = _server_manager.start_server()\n    \n    _solver = ALGSolver(CFG)\n    temp_client = OpenAI(base_url=f'http://0.0.0.0:{CFG.server_port}/v1', api_key='sk-local')\n    _server_manager.wait_for_server(temp_client, CFG.server_timeout)\n    _solver.initialize()\n    \n    return _solver\n\ndef predict(id_, question):\n    id_value = id_.item(0) if hasattr(id_, 'item') else str(id_)\n    question_text = question.item(0) if hasattr(question, 'item') else str(question)\n    \n    print('\\n' + '='*60)\n    print(f'PROBLEM ID: {id_value}')\n    print('='*60)\n    \n    solver = initialize_solver()\n    result = solver.solve(question_text)\n    answer = result.answer if result.answer is not None else 0\n    \n    print(f'\\n[Kaggle] SUBMITTING: {answer}')\n    return pl.DataFrame({'id': id_value, 'answer': int(answer)})\n\nprint('Kaggle interface defined')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "main",
   "cell_type": "code",
   "source": "# ============================================================\n# MAIN\n# ============================================================\n\nif __name__ == '__main__' or True:\n    if os.path.exists('/kaggle'):\n        import pandas as pd\n        ref_path = '/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv'\n        ref_df = pd.read_csv(ref_path, usecols=[0, 1])\n        ref_df.columns = ['id', 'question']\n        test_path = '/kaggle/working/test.csv'\n        ref_df.to_csv(test_path, index=False)\n        print(f'[Kaggle] Using reference.csv: {len(ref_df)} problems')\n        \n        server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n        if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n            server.serve()\n        else:\n            server.run_local_gateway((test_path,))\n    else:\n        print('[Local] Not on Kaggle - use predict() manually')",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}